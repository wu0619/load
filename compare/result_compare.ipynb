{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "RESULT_DIR = \"./result/\"\n",
    "TEST_PLOT_DIR = \"./plots/\"\n",
    "load_col = 'out.site_energy.total.energy_consumption.kwh'\n",
    "# MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        96783.589350\n",
       "1        97411.955013\n",
       "2        98471.266660\n",
       "3        99516.538686\n",
       "4        97957.806899\n",
       "             ...     \n",
       "35035    98582.780350\n",
       "35036    98693.526323\n",
       "35037    97083.021398\n",
       "35038    96588.769233\n",
       "35039    96596.935578\n",
       "Name: out.site_energy.total.energy_consumption.kwh, Length: 35040, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "display(data[load_col])\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data[load_col] = data[load_col] * 4 / 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[load_col].to_numpy().reshape(-1, 1))\n",
    "data[load_col] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 96\n",
    "height = 8\n",
    "width = 12\n",
    "n_days = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageCoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['timestamp'].min() + DateOffset(days=3)\n",
    "        end = self.X['timestamp'].max() - DateOffset(minutes=96*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def __make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def __make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            training_data = self.X[(self.X['timestamp'] >= training_start_b) & (self.X['timestamp'] <= training_end)]\n",
    "            target_data = self.X[(self.X['timestamp'] >= target_start) & (self.X['timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data[load_col])\n",
    "                self.X_timestamp.append(training_data['timestamp'])\n",
    "                self.y_timestamp.append(target_data['timestamp'])\n",
    "                training_reshaped = np.array(training_data[load_col]).reshape(self.d_b, self.h, self.m)\n",
    "                # symmetric_3d = self.__make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(training_reshaped)\n",
    "                target_reshaped = np.array(target_data[load_col]).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                # symmetric_2d = self.__make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(target_reshaped.flatten())\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets\n",
    "    \n",
    "    \"\"\"calculate the final output of model prediction\"\"\"\n",
    "    def __sum_np(self, matrix):\n",
    "        n_pairs = len(matrix) // 2\n",
    "        sums = []\n",
    "        for i in range(n_pairs):\n",
    "            sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        if len(matrix) % 2 != 0:\n",
    "            sums.append(matrix[n_pairs])\n",
    "\n",
    "        return [num for row in sums for num in row]\n",
    "    \n",
    "    def __x_timeseries_to_image(self, vector):\n",
    "        matrix_1d = vector.reshape(self.d_b, self.h, self.m)\n",
    "        image = self.__make_it_symmetric_3d(matrix_1d)\n",
    "        return image\n",
    "    \n",
    "    def pairwise_sum(self, matrix):\n",
    "        summed_3d_np = np.array([self.__sum_np(layer) for layer in matrix]) / 2\n",
    "        return summed_3d_np\n",
    "    \n",
    "    \"\"\"Use predictions from previous steps to add new inputs to rolling predictions\"\"\"\n",
    "    def image_shift(self, original_input, new_input):\n",
    "        input = np.transpose(original_input, (0, 3, 1, 2))\n",
    "        output = []\n",
    "        output.append(self.pairwise_sum(input[0]))\n",
    "        output = np.array(output).flatten()\n",
    "        output = np.concatenate([output, new_input], axis=0)[-len(output):]\n",
    "        image = self.__x_timeseries_to_image(output)\n",
    "        image = image.reshape(1, *image.shape)\n",
    "        image = np.transpose(image, (0, 2, 3, 1))\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 96\n",
      "Ls: 96\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageCoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days=n_days,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34656, 8, 12, 3)\n",
      "(34656, 96)\n",
      "(34656, 288)\n",
      "(34656, 288)\n",
      "(34656, 96)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 8, 12, 3)\n",
      "(4608, 8, 12, 3)\n",
      "(30048, 96)\n",
      "(4608, 96)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 96)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhaCIA_TCN = pd.read_csv(RESULT_DIR+\"PhaCIA_TCN.csv\", index_col=0)\n",
    "ETR = pd.read_csv(RESULT_DIR+\"etr.csv\", index_col=0)\n",
    "CNN = pd.read_csv(RESULT_DIR+\"Image_CNN.csv\", index_col=0)\n",
    "SVR = pd.read_csv(RESULT_DIR+\"SVR.csv\", index_col=0)\n",
    "XGB = pd.read_csv(RESULT_DIR+\"XGBoost.csv\", index_col=0)\n",
    "Proposed = pd.read_csv(RESULT_DIR+\"proposed_rolling16.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_error(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"-\" * 86)\n",
    "    print(f'mse: {mse:.4f}')\n",
    "    print(f'rmse: {rmse:.4f}')\n",
    "    print(f'mae: {mae:.4f}')\n",
    "    print(f'mape: {mape: .4f}')\n",
    "    print(f'r2: {r2:.4f}')\n",
    "    print(\"-\" * 86)\n",
    "\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "    mse_inv = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    rmse_inv = math.sqrt(mse_inv)\n",
    "    mae_inv = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    mape_inv = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "    r2_inv = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    print(\"-\" * 86)\n",
    "    print(f'mse_inv: {mse_inv:.4f}')\n",
    "    print(f'rmse_inv: {rmse_inv:.4f}')\n",
    "    print(f'mae_inv: {mae_inv:.4f}')\n",
    "    print(f'mape_inv: {mape_inv: .4f}')\n",
    "    print(f'r2_inv: {r2_inv:.4f}')\n",
    "    print(\"-\" * 86)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
