{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "RESULT_DIR = \"./result/\"\n",
    "TEST_PLOT_DIR = \"./plots/\"\n",
    "load_col = 'out.site_energy.total.energy_consumption.kwh'\n",
    "# MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data[load_col] = data[load_col] * 4 / 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[load_col].to_numpy().reshape(-1, 1))\n",
    "data[load_col] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageCoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['timestamp'].min() + DateOffset(days=self.d_b)\n",
    "        end = self.X['timestamp'].max() - DateOffset(minutes=96*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def __make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def __make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            training_data = self.X[(self.X['timestamp'] >= training_start_b) & (self.X['timestamp'] <= training_end)]\n",
    "            target_data = self.X[(self.X['timestamp'] >= target_start) & (self.X['timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data[load_col])\n",
    "                self.X_timestamp.append(training_data['timestamp'])\n",
    "                self.y_timestamp.append(target_data['timestamp'])\n",
    "                training_reshaped = np.array(training_data[load_col]).reshape(self.d_b, self.h, self.m)\n",
    "                # symmetric_3d = self.__make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(training_reshaped)\n",
    "                target_reshaped = np.array(target_data[load_col]).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                # symmetric_2d = self.__make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(target_reshaped.flatten())\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets\n",
    "\n",
    "    \"\"\"Use predictions from previous steps to add new inputs to rolling predictions\"\"\"\n",
    "    def image_shift(self, original_input, new_input):\n",
    "        input = np.transpose(original_input, (0, 3, 1, 2))\n",
    "        output = []\n",
    "        output.append(input[0])\n",
    "        output = np.array(output).flatten()\n",
    "        output = np.concatenate([output, new_input.flatten()], axis=0)[-len(output):]\n",
    "        image = output.reshape(self.d_b, self.h, self.m)\n",
    "        image = image.reshape(1, *image.shape)\n",
    "        image = np.transpose(image, (0, 2, 3, 1))\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TimeSeriesImageCoder(\n",
    "    X=data,\n",
    "    n_predict=96,\n",
    "    height=8,\n",
    "    width=12,\n",
    "    n_days=3,\n",
    "    n_window_shift=\"15min\"\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_5 = TimeSeriesImageCoder(\n",
    "#     X=data,\n",
    "#     n_predict=96,\n",
    "#     height=8,\n",
    "#     width=12,\n",
    "#     n_days=5,\n",
    "#     n_window_shift=\"15min\"\n",
    "# )\n",
    "# encoded_Xb_5, encoded_y_5 = encoder_5.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_7 = TimeSeriesImageCoder(\n",
    "#     X=data,\n",
    "#     n_predict=96,\n",
    "#     height=8,\n",
    "#     width=12,\n",
    "#     n_days=7,\n",
    "#     n_window_shift=\"15min\"\n",
    "# )\n",
    "# encoded_Xb_7, encoded_y_7 = encoder_7.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)\n",
    "\n",
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n",
    " \n",
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n",
    "\n",
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y\n",
    "\n",
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_err(y_test, y_pred):\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "    mse_inv = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    rmse_inv = math.sqrt(mse_inv)\n",
    "    mae_inv = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    mape_inv = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "    r2_inv = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    print(\"-\" * 86)\n",
    "    print(f'mse_inv: {mse_inv:.4f}')\n",
    "    print(f'rmse_inv: {rmse_inv:.4f}')\n",
    "    print(f'mae_inv: {mae_inv:.4f}')\n",
    "    print(f'mape_inv: {mape_inv: .4f}')\n",
    "    print(f'r2_inv: {r2_inv:.4f}')\n",
    "    print(\"-\" * 86)\n",
    "\n",
    "def cal_err_per_step(y_test, y_pred):\n",
    "    n_steps = y_pred.shape[1]  # 預測步數\n",
    "\n",
    "    mse = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    mape = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        true_step = y_pred[:, i]\n",
    "        predicted_step = y_test[:, i]\n",
    "\n",
    "        mse_step = mean_squared_error(true_step, predicted_step)\n",
    "        rmse_step = np.sqrt(mse_step)\n",
    "        mae_step = mean_absolute_error(true_step, predicted_step)\n",
    "        mape_step = mean_absolute_percentage_error(true_step, predicted_step) * 100\n",
    "\n",
    "        mse.append(mse_step)\n",
    "        rmse.append(rmse_step)\n",
    "        mae.append(mae_step)\n",
    "        mape.append(mape_step)\n",
    "\n",
    "    return mse, rmse, mae, mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"./result/proposed_96.csv\", index_col=0).to_numpy()\n",
    "PhaCIA_TCN = pd.read_csv(\"./result/PhaCIA_TCN.csv\", index_col=0).to_numpy()\n",
    "Image_CNN = pd.read_csv(\"./result/Image_CNN.csv\", index_col=0).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_err(y_test, proposed)\n",
    "cal_err(y_test, PhaCIA_TCN)\n",
    "cal_err(y_test, Image_CNN)\n",
    "\n",
    "results = {\n",
    "    \"proposed\": cal_err_per_step(y_test, proposed),\n",
    "    \"PhaCIA_TCN\": cal_err_per_step(y_test, PhaCIA_TCN),\n",
    "    \"Image_CNN\": cal_err_per_step(y_test, Image_CNN)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['font.family'] = 'Times New Roman'\n",
    "# plt.figure(figsize=(12, 7.5))\n",
    "# plt.title('Comparison of Different Model MAPE for Each Step', fontsize=18)\n",
    "# plt.plot(results[\"proposed\"][-1], label=\"Proposed\")\n",
    "# plt.plot(results[\"PhaCIA_TCN\"][-1], label=\"PhaCIA-TCNs [48]\")\n",
    "# plt.plot(results[\"Image_CNN\"][-1], label=\"STI-CNN [49]\")\n",
    "# plt.legend(fontsize=14)\n",
    "# plt.xlabel(\"Steps\", fontsize=14)\n",
    "# plt.ylabel(\"MAPE (%)\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"Different_Model_MAPE.png\", dpi=1300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data1 = scaler.inverse_transform(proposed)\n",
    "pred_data2 = scaler.inverse_transform(Image_CNN)\n",
    "actual_data = scaler.inverse_transform(y_test)\n",
    "previous_data = scaler.inverse_transform(X_test_b_flatten)\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "for i in range(actual_data.shape[0]):\n",
    "    if i in [187, 231, 628, 1145, 1508, 1903, 2491, 2628, 3176, 3453, 4029, 4223, 4511]:\n",
    "        history = None\n",
    "        history_timestamp = None\n",
    "        index = i % 192\n",
    "        if index < 47:\n",
    "            history = pred_data2[i-index:i+1, 0]\n",
    "            history_timestamp = y_test_timestamp[i-index:i+1, 0]\n",
    "        else:\n",
    "            history = pred_data2[i-48:i+1, 0]\n",
    "            history_timestamp = y_test_timestamp[i-48:i+1, 0]\n",
    "            \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        X1 = np.concatenate((X_test_b_timestamp[i][-48:], y_test_timestamp[i]))\n",
    "        y1 = np.concatenate((previous_data[i][-48:], actual_data[i]))\n",
    "        X2 = y_test_timestamp[i]\n",
    "        y_p1 = pred_data1[i]\n",
    "        y_p2 = pred_data2[i]\n",
    "        y_a = actual_data[i]\n",
    "        Xh = np.full(700, X1[len(X1)-96])\n",
    "        yh = np.arange(0, 700, 1)\n",
    "        plt.title(f\"Day Ahead Forecasting Starting From {pd.to_datetime(X2[0]).strftime('%m/%d %H:%M')}\", fontsize=18)\n",
    "        plt.plot(X1, y1, '.-', label='Actual', color='#6eb5c0')\n",
    "        plt.plot(X2, y_p1, '.-', label='Predicted', color='#1167b1')\n",
    "        # plt.plot(X2, y_p2, '.-', label='Rolling Forecasting', color='#03264c')\n",
    "        plt.plot(history_timestamp, history, '--', label='Rolling Forecasting History', color='#989898')\n",
    "        plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "        plt.ylim(0, 700)\n",
    "        plt.xlabel('Time step', fontsize=14)\n",
    "        plt.ylabel('Usage (kWh)', fontsize=14)\n",
    "        plt.legend(loc='lower left', bbox_to_anchor=(1, 0), fontsize=11)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\", dpi=1300)\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
