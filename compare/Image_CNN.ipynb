{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 16:58:02.329956: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 16:58:02.351739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 16:58:02.351768: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 16:58:02.351779: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 16:58:02.356163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse.linalg import cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 16:58:03.531195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.531299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.533986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.534096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.534178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.534245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.535609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.535706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.535774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.569092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.569194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.569269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 16:58:03.569341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 114 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "TEST_PLOT_DIR = \"./result/STI_CNN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_col = 'out.site_energy.total.energy_consumption.kwh'\n",
    "# MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data[load_col] = data[load_col] * 4 / 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[load_col].to_numpy().reshape(-1, 1))\n",
    "data[load_col] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.307914\n",
       "1        0.313486\n",
       "2        0.322878\n",
       "3        0.332147\n",
       "4        0.318326\n",
       "           ...   \n",
       "35035    0.323867\n",
       "35036    0.324849\n",
       "35037    0.310569\n",
       "35038    0.306187\n",
       "35039    0.306259\n",
       "Name: out.site_energy.total.energy_consumption.kwh, Length: 35040, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[load_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upgrade</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>models_used</th>\n",
       "      <th>floor_area_represented</th>\n",
       "      <th>out.district_cooling.cooling.energy_consumption.kwh</th>\n",
       "      <th>out.district_heating.heating.energy_consumption.kwh</th>\n",
       "      <th>out.district_heating.water_systems.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.cooling.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.exterior_lighting.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.fans.energy_consumption.kwh</th>\n",
       "      <th>...</th>\n",
       "      <th>out.electricity.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.natural_gas.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.district_heating.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.natural_gas.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.heating.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.interior_equipment.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.water_systems.energy_consumption.kwh.savings</th>\n",
       "      <th>out.site_energy.total.energy_consumption.kwh.savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>3.504000e+04</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-07-02 12:07:30</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>351.077590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10702.802560</td>\n",
       "      <td>3606.591142</td>\n",
       "      <td>20721.475338</td>\n",
       "      <td>...</td>\n",
       "      <td>4979.811962</td>\n",
       "      <td>23848.451624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28859.420341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.378723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16646.463233</td>\n",
       "      <td>...</td>\n",
       "      <td>-28508.867274</td>\n",
       "      <td>262.091277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3108.391514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-04-02 06:11:15</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>56.488275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2706.386049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19725.608356</td>\n",
       "      <td>...</td>\n",
       "      <td>-529.918116</td>\n",
       "      <td>8719.805585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17223.696432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-07-02 12:07:30</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>259.402965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7965.151518</td>\n",
       "      <td>3546.633502</td>\n",
       "      <td>20458.531255</td>\n",
       "      <td>...</td>\n",
       "      <td>2273.919309</td>\n",
       "      <td>18191.504378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23244.709423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-10-01 18:03:45</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>574.228447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15479.805245</td>\n",
       "      <td>7127.583771</td>\n",
       "      <td>21985.597167</td>\n",
       "      <td>...</td>\n",
       "      <td>9286.504567</td>\n",
       "      <td>32494.864830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35158.530405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>1559.617664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55401.017935</td>\n",
       "      <td>7361.098134</td>\n",
       "      <td>24359.717506</td>\n",
       "      <td>...</td>\n",
       "      <td>40740.822629</td>\n",
       "      <td>159204.018407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136399.915739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.960550e-08</td>\n",
       "      <td>331.710202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898.426784</td>\n",
       "      <td>3564.157927</td>\n",
       "      <td>1548.734876</td>\n",
       "      <td>...</td>\n",
       "      <td>8136.228348</td>\n",
       "      <td>20711.247693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17025.161426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       upgrade            timestamp  models_used  floor_area_represented  \\\n",
       "count  35040.0                35040      35040.0            3.504000e+04   \n",
       "mean      18.0  2018-07-02 12:07:30        535.0            2.933235e+08   \n",
       "min       18.0  2018-01-01 00:15:00        535.0            2.933235e+08   \n",
       "25%       18.0  2018-04-02 06:11:15        535.0            2.933235e+08   \n",
       "50%       18.0  2018-07-02 12:07:30        535.0            2.933235e+08   \n",
       "75%       18.0  2018-10-01 18:03:45        535.0            2.933235e+08   \n",
       "max       18.0  2019-01-01 00:00:00        535.0            2.933235e+08   \n",
       "std        0.0                  NaN          0.0            5.960550e-08   \n",
       "\n",
       "       out.district_cooling.cooling.energy_consumption.kwh  \\\n",
       "count                                       35040.000000     \n",
       "mean                                          351.077590     \n",
       "min                                             0.000000     \n",
       "25%                                            56.488275     \n",
       "50%                                           259.402965     \n",
       "75%                                           574.228447     \n",
       "max                                          1559.617664     \n",
       "std                                           331.710202     \n",
       "\n",
       "       out.district_heating.heating.energy_consumption.kwh  \\\n",
       "count                                            35040.0     \n",
       "mean                                                 0.0     \n",
       "min                                                  0.0     \n",
       "25%                                                  0.0     \n",
       "50%                                                  0.0     \n",
       "75%                                                  0.0     \n",
       "max                                                  0.0     \n",
       "std                                                  0.0     \n",
       "\n",
       "       out.district_heating.water_systems.energy_consumption.kwh  \\\n",
       "count                                            35040.0           \n",
       "mean                                                 0.0           \n",
       "min                                                  0.0           \n",
       "25%                                                  0.0           \n",
       "50%                                                  0.0           \n",
       "75%                                                  0.0           \n",
       "max                                                  0.0           \n",
       "std                                                  0.0           \n",
       "\n",
       "       out.electricity.cooling.energy_consumption.kwh  \\\n",
       "count                                    35040.000000   \n",
       "mean                                     10702.802560   \n",
       "min                                        326.378723   \n",
       "25%                                       2706.386049   \n",
       "50%                                       7965.151518   \n",
       "75%                                      15479.805245   \n",
       "max                                      55401.017935   \n",
       "std                                       9898.426784   \n",
       "\n",
       "       out.electricity.exterior_lighting.energy_consumption.kwh  \\\n",
       "count                                       35040.000000          \n",
       "mean                                         3606.591142          \n",
       "min                                             0.000000          \n",
       "25%                                             0.000000          \n",
       "50%                                          3546.633502          \n",
       "75%                                          7127.583771          \n",
       "max                                          7361.098134          \n",
       "std                                          3564.157927          \n",
       "\n",
       "       out.electricity.fans.energy_consumption.kwh  ...  \\\n",
       "count                                 35040.000000  ...   \n",
       "mean                                  20721.475338  ...   \n",
       "min                                   16646.463233  ...   \n",
       "25%                                   19725.608356  ...   \n",
       "50%                                   20458.531255  ...   \n",
       "75%                                   21985.597167  ...   \n",
       "max                                   24359.717506  ...   \n",
       "std                                    1548.734876  ...   \n",
       "\n",
       "       out.electricity.total.energy_consumption.kwh.savings  \\\n",
       "count                                       35040.000000      \n",
       "mean                                         4979.811962      \n",
       "min                                        -28508.867274      \n",
       "25%                                          -529.918116      \n",
       "50%                                          2273.919309      \n",
       "75%                                          9286.504567      \n",
       "max                                         40740.822629      \n",
       "std                                          8136.228348      \n",
       "\n",
       "       out.natural_gas.total.energy_consumption.kwh.savings  \\\n",
       "count                                       35040.000000      \n",
       "mean                                        23848.451624      \n",
       "min                                           262.091277      \n",
       "25%                                          8719.805585      \n",
       "50%                                         18191.504378      \n",
       "75%                                         32494.864830      \n",
       "max                                        159204.018407      \n",
       "std                                         20711.247693      \n",
       "\n",
       "       out.district_heating.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0             \n",
       "mean                                                 0.0             \n",
       "min                                                  0.0             \n",
       "25%                                                  0.0             \n",
       "50%                                                  0.0             \n",
       "75%                                                  0.0             \n",
       "max                                                  0.0             \n",
       "std                                                  0.0             \n",
       "\n",
       "       out.natural_gas.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0        \n",
       "mean                                                 0.0        \n",
       "min                                                  0.0        \n",
       "25%                                                  0.0        \n",
       "50%                                                  0.0        \n",
       "75%                                                  0.0        \n",
       "max                                                  0.0        \n",
       "std                                                  0.0        \n",
       "\n",
       "       out.other_fuel.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0       \n",
       "mean                                                 0.0       \n",
       "min                                                  0.0       \n",
       "25%                                                  0.0       \n",
       "50%                                                  0.0       \n",
       "75%                                                  0.0       \n",
       "max                                                  0.0       \n",
       "std                                                  0.0       \n",
       "\n",
       "       out.other_fuel.heating.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0       \n",
       "mean                                                 0.0       \n",
       "min                                                  0.0       \n",
       "25%                                                  0.0       \n",
       "50%                                                  0.0       \n",
       "75%                                                  0.0       \n",
       "max                                                  0.0       \n",
       "std                                                  0.0       \n",
       "\n",
       "       out.other_fuel.interior_equipment.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0                  \n",
       "mean                                                 0.0                  \n",
       "min                                                  0.0                  \n",
       "25%                                                  0.0                  \n",
       "50%                                                  0.0                  \n",
       "75%                                                  0.0                  \n",
       "max                                                  0.0                  \n",
       "std                                                  0.0                  \n",
       "\n",
       "       out.other_fuel.total.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0     \n",
       "mean                                                 0.0     \n",
       "min                                                  0.0     \n",
       "25%                                                  0.0     \n",
       "50%                                                  0.0     \n",
       "75%                                                  0.0     \n",
       "max                                                  0.0     \n",
       "std                                                  0.0     \n",
       "\n",
       "       out.other_fuel.water_systems.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0             \n",
       "mean                                                 0.0             \n",
       "min                                                  0.0             \n",
       "25%                                                  0.0             \n",
       "50%                                                  0.0             \n",
       "75%                                                  0.0             \n",
       "max                                                  0.0             \n",
       "std                                                  0.0             \n",
       "\n",
       "       out.site_energy.total.energy_consumption.kwh.savings  \n",
       "count                                       35040.000000     \n",
       "mean                                        28859.420341     \n",
       "min                                          3108.391514     \n",
       "25%                                         17223.696432     \n",
       "50%                                         23244.709423     \n",
       "75%                                         35158.530405     \n",
       "max                                        136399.915739     \n",
       "std                                         17025.161426     \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 96\n",
    "height = 18\n",
    "width = 16\n",
    "n_days = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageCoder():\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['timestamp'].min() + DateOffset(days=3)\n",
    "        end = self.X['timestamp'].max() - DateOffset(minutes=96*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def __make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def __make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            training_data = self.X[(self.X['timestamp'] >= training_start_b) & (self.X['timestamp'] <= training_end)]\n",
    "            target_data = self.X[(self.X['timestamp'] >= target_start) & (self.X['timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data[load_col])\n",
    "                self.X_timestamp.append(training_data['timestamp'])\n",
    "                self.y_timestamp.append(target_data['timestamp'])\n",
    "                training_reshaped = np.array(training_data[load_col]).reshape(1, self.h, self.m)\n",
    "                training_sets.append(training_reshaped)\n",
    "                target_reshaped = np.array(target_data[load_col]).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                target_sets.append(target_reshaped.flatten())\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets\n",
    "    \n",
    "    \"\"\"calculate the final output of model prediction\"\"\"\n",
    "    def __sum_np(self, matrix):\n",
    "        n_pairs = len(matrix) // 2\n",
    "        sums = []\n",
    "        for i in range(n_pairs):\n",
    "            sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        if len(matrix) % 2 != 0:\n",
    "            sums.append(matrix[n_pairs])\n",
    "\n",
    "        return [num for row in sums for num in row]\n",
    "    \n",
    "    def __x_timeseries_to_image(self, vector):\n",
    "        matrix_1d = vector.reshape(self.d_b, self.h, self.m)\n",
    "        image = self.__make_it_symmetric_3d(matrix_1d)\n",
    "        return image\n",
    "    \n",
    "    def pairwise_sum(self, matrix):\n",
    "        summed_3d_np = np.array([self.__sum_np(layer) for layer in matrix]) / 2\n",
    "        return summed_3d_np\n",
    "    \n",
    "    \"\"\"Use predictions from previous steps to add new inputs to rolling predictions\"\"\"\n",
    "    def image_shift(self, original_input, new_input):\n",
    "        input = np.transpose(original_input, (0, 3, 1, 2))\n",
    "        output = []\n",
    "        output.append(self.pairwise_sum(input[0]))\n",
    "        output = np.array(output).flatten()\n",
    "        output = np.concatenate([output, new_input], axis=0)[-len(output):]\n",
    "        image = self.__x_timeseries_to_image(output)\n",
    "        image = image.reshape(1, *image.shape)\n",
    "        image = np.transpose(image, (0, 2, 3, 1))\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 288\n",
      "Ls: 96\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageCoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days=n_days,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34656, 18, 16, 1)\n",
      "(34656, 96)\n",
      "(34656, 288)\n",
      "(34656, 288)\n",
      "(34656, 96)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 18, 16, 1)\n",
      "(4608, 18, 16, 1)\n",
      "(30048, 96)\n",
      "(4608, 96)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 96)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_b, encoder):\n",
    "    height, width = math.ceil(encoder.n_predict / encoder.m), min(encoder.n_predict, encoder.m)\n",
    "    inputs_b = Input(shape=input_shape_b)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "    maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(conv1)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(maxpool1)\n",
    "    maxpool2 = MaxPooling2D(pool_size=10, padding=\"same\")(conv2)\n",
    "    flatten1 = Flatten()(maxpool2)\n",
    "    outputs = Dense(height*width, activation=\"linear\")(flatten1)\n",
    "    print(height*width)\n",
    "    model = Model(inputs=inputs_b, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 18, 16, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 18, 16, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 2, 2, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                6240      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25056 (97.88 KB)\n",
      "Trainable params: 25056 (97.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = create_model(input_shape_b=X_train_b.shape[1:], encoder=encoder)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 16:58:29.667563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0884 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0340 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0323 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0317 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0309 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0300 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0289 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0274 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0258 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0241 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0222 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0203 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0183 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0165 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0151 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0140 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0131 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0122 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0116 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0110 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0104 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0095 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0092 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0088 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0085 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0082 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0079 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0076 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0074 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0071 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0069 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0067 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0065 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0063 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0061 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0051 - lr: 5.0000e-05\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0051 - lr: 5.0000e-05\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0050 - lr: 5.0000e-05\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0049 - lr: 5.0000e-05\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0048 - lr: 5.0000e-05\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0046 - lr: 5.0000e-05\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 90/120\n",
      "302/313 [===========================>..] - ETA: 0s - loss: 0.0033\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 1.5000e-05\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 1.5000e-05\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 1.5000e-05\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - lr: 1.5000e-05\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 1.5000e-05\n",
      "Epoch 96/120\n",
      "296/313 [===========================>..] - ETA: 0s - loss: 0.0032\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 1.5000e-05\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 4.5000e-06\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 4.5000e-06\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 4.5000e-06\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 4.5000e-06\n",
      "Epoch 101/120\n",
      "303/313 [============================>.] - ETA: 0s - loss: 0.0032\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 4.5000e-06\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 1.3500e-06\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 1.3500e-06\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 1.3500e-06\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0032 - lr: 1.3500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_b,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/144 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 577us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 96)\n",
      "(4608, 96)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0037\n",
      "rmse: 0.0608\n",
      "mae: 0.0434\n",
      "mape:  0.1787\n",
      "r2: 0.8771\n",
      "--------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------\n",
      "mse_inv: 751.1902\n",
      "rmse_inv: 27.4078\n",
      "mae_inv: 19.5664\n",
      "mape_inv:  0.0504\n",
      "r2_inv: 0.8771\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'mape: {mape: .4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)\n",
    "\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "mse_inv = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse_inv = math.sqrt(mse_inv)\n",
    "mae_inv = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mape_inv = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "r2_inv = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse_inv: {mse_inv:.4f}')\n",
    "print(f'rmse_inv: {rmse_inv:.4f}')\n",
    "print(f'mae_inv: {mae_inv:.4f}')\n",
    "print(f'mape_inv: {mape_inv: .4f}')\n",
    "print(f'r2_inv: {r2_inv:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_per_steps(true_values, predicted_values):\n",
    "    n_steps = true_values.shape[1]\n",
    "\n",
    "    mse = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    mape = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        true_step = true_values[:, i]\n",
    "        predicted_step = predicted_values[:, i]\n",
    "\n",
    "        mse_step = mean_squared_error(true_step, predicted_step)\n",
    "        rmse_step = np.sqrt(mse_step)\n",
    "        mae_step = mean_absolute_error(true_step, predicted_step)\n",
    "        mape_step = mean_absolute_percentage_error(true_step, predicted_step)\n",
    "\n",
    "        mse.append(mse_step)\n",
    "        rmse.append(rmse_step)\n",
    "        mae.append(mae_step)\n",
    "        mape.append(mape_step)\n",
    "\n",
    "    return np.array(mse), np.array(rmse), np.array(mae), np.array(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_per_steps, rmse_per_steps, mae_per_steps, mape_per_steps = calculate_metrics_per_steps(y_test_inv, y_pred_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 292.78717206  349.48879879  402.24469435  438.23710047  442.83892502\n",
      "  424.1372282   439.97540231  453.62490692  497.08253989  523.16043986\n",
      "  566.4861873   578.47578343  617.52773389  631.64183177  659.36559386\n",
      "  658.58960087  712.64871286  742.1449101   776.29718686  765.33903204\n",
      "  776.60871816  797.37604161  783.1104408   812.27236687  896.17315763\n",
      "  915.36417196  875.17703207  873.60328909  846.08715717  852.33849661\n",
      "  898.05621446  907.60150045  908.70172783  929.26654776  953.00421016\n",
      "  971.06140423  952.67035287  986.1319042  1001.57476962  929.76675487\n",
      "  949.51537834  946.49176549  955.92425816  978.98102675  994.084917\n",
      "  989.93341313 1003.63965638 1006.31400136  991.35289319  979.87207836\n",
      "  962.8570051   952.28462114  960.15681524  945.24292407  923.30370439\n",
      "  886.16655444  889.72011074  892.56720646  888.04603537  837.33699334\n",
      "  835.05468671  807.17480979  780.8539829   759.50817908  738.89133817\n",
      "  738.78893407  704.35577162  719.84211811  715.9501474   689.39760829\n",
      "  709.82689017  700.17640143  665.47138978  705.61524747  708.47380439\n",
      "  702.58028673  669.61753326  662.16692345  658.17524532  634.96398321\n",
      "  644.18868587  654.31653329  662.87926194  642.06425724  638.93640817\n",
      "  634.4487603   600.68230911  610.14923996  614.73522878  615.92981202\n",
      "  616.41915711  610.57804752  608.30506124  623.63815577  622.64444773\n",
      "  635.62907494]\n",
      "[17.11102487 18.69461951 20.05603885 20.93411332 21.04373838 20.59459221\n",
      " 20.97559063 21.29847194 22.29534794 22.87270076 23.8009703  24.05152352\n",
      " 24.85010531 25.13248559 25.67811508 25.66300062 26.69548113 27.24233672\n",
      " 27.86211024 27.66476156 27.86770027 28.23784768 27.98411051 28.5003924\n",
      " 29.93615135 30.2549859  29.58339115 29.55678076 29.08757737 29.19483681\n",
      " 29.96758606 30.12642528 30.14467993 30.48387357 30.87076627 31.16185816\n",
      " 30.86535846 31.40273721 31.6476661  30.49207692 30.81420741 30.7651063\n",
      " 30.91802481 31.2886725  31.52911221 31.46320729 31.68027235 31.72245264\n",
      " 31.48575699 31.30290846 31.02993724 30.85910921 30.98639726 30.7448032\n",
      " 30.38591293 29.76854975 29.82817646 29.87586328 29.80010126 28.93677579\n",
      " 28.89731279 28.41082205 27.94376465 27.55917595 27.18255577 27.18067207\n",
      " 26.5397018  26.82987361 26.75724476 26.25638224 26.64257664 26.46084657\n",
      " 25.79673215 26.56341935 26.61717123 26.50623109 25.87696917 25.73260429\n",
      " 25.65492634 25.19849169 25.38087244 25.57961167 25.74644173 25.3389869\n",
      " 25.27719146 25.18826632 24.50882105 24.70119916 24.79385466 24.81793327\n",
      " 24.82779002 24.70987753 24.66384117 24.97274826 24.95284448 25.21168529]\n",
      "[10.66829528 12.01193432 13.00072977 13.65758572 14.30084688 14.45295177\n",
      " 14.87995926 15.02418077 15.57369257 15.95110695 16.65114613 16.72288339\n",
      " 17.24980593 17.37859005 17.73377504 17.7566942  18.32419616 18.68589012\n",
      " 19.39213191 19.21431619 19.2562322  19.49268549 19.58408885 19.91628055\n",
      " 21.06332114 21.45892603 20.99905318 20.98160626 20.78426426 20.79315679\n",
      " 21.07057074 21.32022779 21.45488394 21.62661126 21.775427   22.49425943\n",
      " 22.27275944 22.50762762 23.03720191 22.04516108 22.22446183 22.16288081\n",
      " 22.5018615  22.63896477 22.7866984  22.95774666 23.0105978  22.82899468\n",
      " 22.57922837 22.62569721 22.67888652 22.58857529 22.66565427 22.66364861\n",
      " 22.49934213 22.0780844  22.06648837 22.08964596 22.24411189 21.70680146\n",
      " 21.45569766 21.09532188 20.56934956 20.40803649 20.12482582 19.86835099\n",
      " 19.66573869 19.61797299 19.52914357 19.30368542 19.70698685 19.48626083\n",
      " 19.07467118 19.51927784 19.66718911 19.55449588 19.24293426 18.99200046\n",
      " 19.03444799 18.53018027 18.547435   18.44790957 18.62958625 18.28914635\n",
      " 18.09796573 18.332252   17.96164831 18.15518365 17.91653074 17.90301384\n",
      " 17.88407023 18.035096   18.04484566 18.44622127 18.39054016 18.68741928]\n",
      "[0.02786413 0.03136965 0.03389458 0.03558243 0.03717798 0.03740702\n",
      " 0.03842811 0.03896528 0.04048467 0.04126913 0.04322559 0.04324881\n",
      " 0.04466063 0.04500942 0.04582139 0.04604855 0.04749918 0.04845032\n",
      " 0.05037797 0.04984146 0.04988671 0.05058789 0.05099038 0.05191755\n",
      " 0.05502649 0.05624338 0.05485838 0.05501275 0.05431792 0.05441856\n",
      " 0.05556609 0.05624251 0.0561531  0.05677775 0.05709715 0.05877269\n",
      " 0.05790475 0.05857304 0.05994364 0.05723714 0.0576959  0.05717373\n",
      " 0.05795585 0.05844845 0.05866243 0.05917894 0.05924701 0.05849681\n",
      " 0.05778406 0.05809559 0.05798307 0.05787907 0.05808173 0.05792242\n",
      " 0.05762084 0.05641701 0.05652067 0.05636295 0.05700384 0.05559136\n",
      " 0.05493012 0.05405392 0.0527715  0.05220535 0.05140888 0.0507004\n",
      " 0.05024615 0.049999   0.0497264  0.04902504 0.04975314 0.04922675\n",
      " 0.04834169 0.04935817 0.04984117 0.04947986 0.04883147 0.04816375\n",
      " 0.04821842 0.04699855 0.04716087 0.0468462  0.04745178 0.0467852\n",
      " 0.04624655 0.04704703 0.04622576 0.04679358 0.04624813 0.04596618\n",
      " 0.04591363 0.04637003 0.04610237 0.04724457 0.04717617 0.04764967]\n"
     ]
    }
   ],
   "source": [
    "print(mse_per_steps)\n",
    "print(rmse_per_steps)\n",
    "print(mae_per_steps)\n",
    "print(mape_per_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/image_CNN_96steps.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = \"./result/\"\n",
    "result_df = pd.DataFrame(y_pred)\n",
    "result_df.to_csv(RESULT_DIR+\"Image_CNN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
