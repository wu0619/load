{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:13:04.541226: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-14 11:13:04.561171: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-14 11:13:04.561193: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-14 11:13:04.561209: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-14 11:13:04.565371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from keras import layers, models, activations\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.saving import register_keras_serializable\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:13:05.486742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.486846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.489468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.489564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.489631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.489695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.491020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.491107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.491172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.534771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.534876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.534950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-14 11:13:05.535016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10527 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "TEST_PLOT_DIR = \"./result/PhaCIA_TCNs/\"\n",
    "load_col = 'out.site_energy.total.energy_consumption.kwh'\n",
    "# MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data[load_col] = data[load_col] * 4 / 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[load_col].to_numpy().reshape(-1, 1))\n",
    "data[load_col] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upgrade</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>models_used</th>\n",
       "      <th>floor_area_represented</th>\n",
       "      <th>out.district_cooling.cooling.energy_consumption.kwh</th>\n",
       "      <th>out.district_heating.heating.energy_consumption.kwh</th>\n",
       "      <th>out.district_heating.water_systems.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.cooling.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.exterior_lighting.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.fans.energy_consumption.kwh</th>\n",
       "      <th>...</th>\n",
       "      <th>out.electricity.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.natural_gas.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.district_heating.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.natural_gas.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.heating.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.interior_equipment.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.water_systems.energy_consumption.kwh.savings</th>\n",
       "      <th>out.site_energy.total.energy_consumption.kwh.savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>3.504000e+04</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-07-02 12:07:30</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>351.077590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10702.802560</td>\n",
       "      <td>3606.591142</td>\n",
       "      <td>20721.475338</td>\n",
       "      <td>...</td>\n",
       "      <td>4979.811962</td>\n",
       "      <td>23848.451624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28859.420341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.378723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16646.463233</td>\n",
       "      <td>...</td>\n",
       "      <td>-28508.867274</td>\n",
       "      <td>262.091277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3108.391514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-04-02 06:11:15</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>56.488275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2706.386049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19725.608356</td>\n",
       "      <td>...</td>\n",
       "      <td>-529.918116</td>\n",
       "      <td>8719.805585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17223.696432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-07-02 12:07:30</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>259.402965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7965.151518</td>\n",
       "      <td>3546.633502</td>\n",
       "      <td>20458.531255</td>\n",
       "      <td>...</td>\n",
       "      <td>2273.919309</td>\n",
       "      <td>18191.504378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23244.709423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-10-01 18:03:45</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>574.228447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15479.805245</td>\n",
       "      <td>7127.583771</td>\n",
       "      <td>21985.597167</td>\n",
       "      <td>...</td>\n",
       "      <td>9286.504567</td>\n",
       "      <td>32494.864830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35158.530405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>1559.617664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55401.017935</td>\n",
       "      <td>7361.098134</td>\n",
       "      <td>24359.717506</td>\n",
       "      <td>...</td>\n",
       "      <td>40740.822629</td>\n",
       "      <td>159204.018407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136399.915739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.960550e-08</td>\n",
       "      <td>331.710202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898.426784</td>\n",
       "      <td>3564.157927</td>\n",
       "      <td>1548.734876</td>\n",
       "      <td>...</td>\n",
       "      <td>8136.228348</td>\n",
       "      <td>20711.247693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17025.161426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       upgrade            timestamp  models_used  floor_area_represented  \\\n",
       "count  35040.0                35040      35040.0            3.504000e+04   \n",
       "mean      18.0  2018-07-02 12:07:30        535.0            2.933235e+08   \n",
       "min       18.0  2018-01-01 00:15:00        535.0            2.933235e+08   \n",
       "25%       18.0  2018-04-02 06:11:15        535.0            2.933235e+08   \n",
       "50%       18.0  2018-07-02 12:07:30        535.0            2.933235e+08   \n",
       "75%       18.0  2018-10-01 18:03:45        535.0            2.933235e+08   \n",
       "max       18.0  2019-01-01 00:00:00        535.0            2.933235e+08   \n",
       "std        0.0                  NaN          0.0            5.960550e-08   \n",
       "\n",
       "       out.district_cooling.cooling.energy_consumption.kwh  \\\n",
       "count                                       35040.000000     \n",
       "mean                                          351.077590     \n",
       "min                                             0.000000     \n",
       "25%                                            56.488275     \n",
       "50%                                           259.402965     \n",
       "75%                                           574.228447     \n",
       "max                                          1559.617664     \n",
       "std                                           331.710202     \n",
       "\n",
       "       out.district_heating.heating.energy_consumption.kwh  \\\n",
       "count                                            35040.0     \n",
       "mean                                                 0.0     \n",
       "min                                                  0.0     \n",
       "25%                                                  0.0     \n",
       "50%                                                  0.0     \n",
       "75%                                                  0.0     \n",
       "max                                                  0.0     \n",
       "std                                                  0.0     \n",
       "\n",
       "       out.district_heating.water_systems.energy_consumption.kwh  \\\n",
       "count                                            35040.0           \n",
       "mean                                                 0.0           \n",
       "min                                                  0.0           \n",
       "25%                                                  0.0           \n",
       "50%                                                  0.0           \n",
       "75%                                                  0.0           \n",
       "max                                                  0.0           \n",
       "std                                                  0.0           \n",
       "\n",
       "       out.electricity.cooling.energy_consumption.kwh  \\\n",
       "count                                    35040.000000   \n",
       "mean                                     10702.802560   \n",
       "min                                        326.378723   \n",
       "25%                                       2706.386049   \n",
       "50%                                       7965.151518   \n",
       "75%                                      15479.805245   \n",
       "max                                      55401.017935   \n",
       "std                                       9898.426784   \n",
       "\n",
       "       out.electricity.exterior_lighting.energy_consumption.kwh  \\\n",
       "count                                       35040.000000          \n",
       "mean                                         3606.591142          \n",
       "min                                             0.000000          \n",
       "25%                                             0.000000          \n",
       "50%                                          3546.633502          \n",
       "75%                                          7127.583771          \n",
       "max                                          7361.098134          \n",
       "std                                          3564.157927          \n",
       "\n",
       "       out.electricity.fans.energy_consumption.kwh  ...  \\\n",
       "count                                 35040.000000  ...   \n",
       "mean                                  20721.475338  ...   \n",
       "min                                   16646.463233  ...   \n",
       "25%                                   19725.608356  ...   \n",
       "50%                                   20458.531255  ...   \n",
       "75%                                   21985.597167  ...   \n",
       "max                                   24359.717506  ...   \n",
       "std                                    1548.734876  ...   \n",
       "\n",
       "       out.electricity.total.energy_consumption.kwh.savings  \\\n",
       "count                                       35040.000000      \n",
       "mean                                         4979.811962      \n",
       "min                                        -28508.867274      \n",
       "25%                                          -529.918116      \n",
       "50%                                          2273.919309      \n",
       "75%                                          9286.504567      \n",
       "max                                         40740.822629      \n",
       "std                                          8136.228348      \n",
       "\n",
       "       out.natural_gas.total.energy_consumption.kwh.savings  \\\n",
       "count                                       35040.000000      \n",
       "mean                                        23848.451624      \n",
       "min                                           262.091277      \n",
       "25%                                          8719.805585      \n",
       "50%                                         18191.504378      \n",
       "75%                                         32494.864830      \n",
       "max                                        159204.018407      \n",
       "std                                         20711.247693      \n",
       "\n",
       "       out.district_heating.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0             \n",
       "mean                                                 0.0             \n",
       "min                                                  0.0             \n",
       "25%                                                  0.0             \n",
       "50%                                                  0.0             \n",
       "75%                                                  0.0             \n",
       "max                                                  0.0             \n",
       "std                                                  0.0             \n",
       "\n",
       "       out.natural_gas.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0        \n",
       "mean                                                 0.0        \n",
       "min                                                  0.0        \n",
       "25%                                                  0.0        \n",
       "50%                                                  0.0        \n",
       "75%                                                  0.0        \n",
       "max                                                  0.0        \n",
       "std                                                  0.0        \n",
       "\n",
       "       out.other_fuel.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0       \n",
       "mean                                                 0.0       \n",
       "min                                                  0.0       \n",
       "25%                                                  0.0       \n",
       "50%                                                  0.0       \n",
       "75%                                                  0.0       \n",
       "max                                                  0.0       \n",
       "std                                                  0.0       \n",
       "\n",
       "       out.other_fuel.heating.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0       \n",
       "mean                                                 0.0       \n",
       "min                                                  0.0       \n",
       "25%                                                  0.0       \n",
       "50%                                                  0.0       \n",
       "75%                                                  0.0       \n",
       "max                                                  0.0       \n",
       "std                                                  0.0       \n",
       "\n",
       "       out.other_fuel.interior_equipment.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0                  \n",
       "mean                                                 0.0                  \n",
       "min                                                  0.0                  \n",
       "25%                                                  0.0                  \n",
       "50%                                                  0.0                  \n",
       "75%                                                  0.0                  \n",
       "max                                                  0.0                  \n",
       "std                                                  0.0                  \n",
       "\n",
       "       out.other_fuel.total.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0     \n",
       "mean                                                 0.0     \n",
       "min                                                  0.0     \n",
       "25%                                                  0.0     \n",
       "50%                                                  0.0     \n",
       "75%                                                  0.0     \n",
       "max                                                  0.0     \n",
       "std                                                  0.0     \n",
       "\n",
       "       out.other_fuel.water_systems.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0             \n",
       "mean                                                 0.0             \n",
       "min                                                  0.0             \n",
       "25%                                                  0.0             \n",
       "50%                                                  0.0             \n",
       "75%                                                  0.0             \n",
       "max                                                  0.0             \n",
       "std                                                  0.0             \n",
       "\n",
       "       out.site_energy.total.energy_consumption.kwh.savings  \n",
       "count                                       35040.000000     \n",
       "mean                                        28859.420341     \n",
       "min                                          3108.391514     \n",
       "25%                                         17223.696432     \n",
       "50%                                         23244.709423     \n",
       "75%                                         35158.530405     \n",
       "max                                        136399.915739     \n",
       "std                                         17025.161426     \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a list of timestamps every 2 hours within the dataset's range\n",
    "def generate_timestamps(data) -> pd.DatetimeIndex:\n",
    "    start = data['timestamp'].min() + DateOffset(days=3)\n",
    "    end = data['timestamp'].max() - DateOffset(minutes=96*15)\n",
    "    timestamps = pd.date_range(start=start, end=end, freq='15min')\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-01-04 00:15:00', '2018-01-04 00:30:00',\n",
      "               '2018-01-04 00:45:00', '2018-01-04 01:00:00',\n",
      "               '2018-01-04 01:15:00', '2018-01-04 01:30:00',\n",
      "               '2018-01-04 01:45:00', '2018-01-04 02:00:00',\n",
      "               '2018-01-04 02:15:00', '2018-01-04 02:30:00',\n",
      "               ...\n",
      "               '2018-12-30 21:45:00', '2018-12-30 22:00:00',\n",
      "               '2018-12-30 22:15:00', '2018-12-30 22:30:00',\n",
      "               '2018-12-30 22:45:00', '2018-12-30 23:00:00',\n",
      "               '2018-12-30 23:15:00', '2018-12-30 23:30:00',\n",
      "               '2018-12-30 23:45:00', '2018-12-31 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=34656, freq='15min')\n"
     ]
    }
   ],
   "source": [
    "timestamps = generate_timestamps(data)\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sets_for_all_timestamps(timestamps, data):\n",
    "    training_sets = []\n",
    "    change_rate_sets = []\n",
    "    target_sets = []\n",
    "    training_sets_time = []\n",
    "    target_sets_time = []\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        # Calculate the range for the current period's data\n",
    "        start_time_current = timestamp - DateOffset(days=2, hours=23, minutes=45)\n",
    "        end_time_current = timestamp\n",
    "\n",
    "        # Calculate the target range (the next 10 steps after the current timestamp)\n",
    "        target_start_time = timestamp + DateOffset(minutes=15)\n",
    "        target_end_time = timestamp + DateOffset(hours=3, minutes=0) \n",
    "\n",
    "        # Filter the data for training and target sets\n",
    "        current_data = data[(data['timestamp'] >= start_time_current) & (data['timestamp'] <= end_time_current)]\n",
    "        target_data = data[(data['timestamp'] >= target_start_time) & (data['timestamp'] <= target_end_time)]\n",
    "\n",
    "        # Combine current and last week data for the training set\n",
    "        training_data = pd.concat([current_data]).reset_index(drop=True)\n",
    "        \n",
    "        # Save the training and target sets\n",
    "        if not training_data.empty and not target_data.empty:\n",
    "            training_sets.append(training_data[load_col])\n",
    "            target_sets.append(target_data[load_col])\n",
    "            training_sets_time.append(list(training_data['timestamp']))\n",
    "            target_sets_time.append(list(target_data['timestamp']))\n",
    "\n",
    "    training_sets = np.array(training_sets)\n",
    "    target_sets = np.array(target_sets)\n",
    "    training_sets_time = np.array(training_sets_time)\n",
    "    target_sets_time = np.array(target_sets_time)\n",
    "\n",
    "    return training_sets, target_sets, training_sets_time, target_sets_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and target sets for all the timestamps\n",
    "training_sets, target_sets, training_sets_time, target_sets_time = generate_sets_for_all_timestamps(timestamps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(timestamps.shape[0] / 24)\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_test_time = []\n",
    "y_test_time = []\n",
    "minList = []\n",
    "maxList = []\n",
    "for i in range(0, 24):\n",
    "    min = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    max = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test.append(training_sets[min:max])\n",
    "    y_test.append(target_sets[min:max])\n",
    "    X_test_time.append(training_sets_time[min:max])\n",
    "    y_test_time.append(target_sets_time[min:max])\n",
    "    training_sets = np.concatenate([training_sets[:min], training_sets[max:]])\n",
    "    target_sets = np.concatenate([target_sets[:min], target_sets[max:]])\n",
    "    training_sets_time = np.concatenate([training_sets_time[:min], training_sets_time[max:]])\n",
    "    target_sets_time = np.concatenate([target_sets_time[:min], target_sets_time[max:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([i for i in X_test])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_time = np.concatenate([i for i in X_test_time])\n",
    "y_test_time = np.concatenate([i for i in y_test_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_sets.reshape(*training_sets.shape, 1)\n",
    "X_test = X_test.reshape(*X_test.shape, 1)\n",
    "y_train = target_sets\n",
    "X_train_time = training_sets_time\n",
    "y_train_time = target_sets_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 288, 1)\n",
      "(4608, 288, 1)\n",
      "(30048, 12)\n",
      "(4608, 12)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_test).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IA Module\n",
    "@register_keras_serializable('InputAttention')\n",
    "class InputAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(InputAttention, self).__init__()\n",
    "        self.linear = layers.Dense(1, activation=None)\n",
    "        self.relu = layers.Dense(1, activation='relu')\n",
    "        self.tanh = layers.Dense(1, activation='tanh')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_output = self.linear(inputs)\n",
    "        relu_output = self.relu(linear_output + inputs)\n",
    "        tanh_output = self.tanh(relu_output + inputs)\n",
    "        attention_weights = tf.nn.softmax(tanh_output, axis=1)\n",
    "        weighted_inputs = inputs * attention_weights\n",
    "        return weighted_inputs\n",
    "\n",
    "# PhaC module\n",
    "@register_keras_serializable('ParallelHybridActivatedConvolution')\n",
    "class ParallelHybridActivatedConvolution(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dilation_rate):\n",
    "        super(ParallelHybridActivatedConvolution, self).__init__()\n",
    "        self.dilated_conv = layers.Conv1D(filters, kernel_size, dilation_rate=dilation_rate, padding='causal')\n",
    "        self.relu = layers.ReLU()\n",
    "        self.tanh = layers.Activation('tanh')\n",
    "        self.conv1x1 = layers.Conv1D(filters, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dilated_conv(inputs)\n",
    "        x_relu = self.relu(x)\n",
    "        x_tanh = self.tanh(x)\n",
    "        x_activated = x_relu * x_tanh\n",
    "        x_residual = self.conv1x1(inputs)\n",
    "        return x_activated + x_residual\n",
    "\n",
    "# PhaCIA-TCNs\n",
    "def build_phacia_tcn(input_shape, filters, kernel_size, dilation_rates, n_predict):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 輸入注意力模塊\n",
    "    x = InputAttention()(inputs)\n",
    "    \n",
    "    # TCN Backbone with PhaC modules\n",
    "    for dilation_rate in dilation_rates:\n",
    "        x = ParallelHybridActivatedConvolution(filters, kernel_size, dilation_rate)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        x = ParallelHybridActivatedConvolution(filters*2, kernel_size, dilation_rate)(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(n_predict*2, activation='linear')(x)\n",
    "    outputs = layers.Dense(n_predict, activation='linear')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [*X_train.shape[1:]]\n",
    "filters = 64\n",
    "kernel_size = 3\n",
    "n_predict = 12\n",
    "dilation_rates = [1, 2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 288, 1)]          0         \n",
      "                                                                 \n",
      " input_attention (InputAtte  (None, 288, 1)            6         \n",
      " ntion)                                                          \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           384       \n",
      " convolution (ParallelHybri                                      \n",
      " dActivatedConvolution)                                          \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_1 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_2 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_3 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_4 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 288, 64)           256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          33024     \n",
      " convolution_5 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_6 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_7 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_8 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_9 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 288, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                884760    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                300       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1248458 (4.76 MB)\n",
      "Trainable params: 1248074 (4.76 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = build_phacia_tcn(input_shape, filters, kernel_size, dilation_rates, n_predict)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:13:54.289575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-06-14 11:13:54.548719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff49f7b4320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-14 11:13:54.548732: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-06-14 11:13:54.551007: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-14 11:13:54.598731: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 22s 58ms/step - loss: 0.0128 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0015 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0014 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.0010 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 0.0010 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 9.9991e-04\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 9.9991e-04 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 8.8141e-04 - lr: 1.5000e-05\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 8.7271e-04 - lr: 1.5000e-05\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 8.5840e-04 - lr: 1.5000e-05\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 8.5873e-04 - lr: 1.5000e-05\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 8.5794e-04 - lr: 1.5000e-05\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 8.5065e-04\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 8.5065e-04 - lr: 1.5000e-05\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 8.1122e-04 - lr: 4.5000e-06\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 8.0521e-04 - lr: 4.5000e-06\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 8.0345e-04 - lr: 4.5000e-06\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 7.9973e-04 - lr: 4.5000e-06\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 7.9630e-04\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 7.9630e-04 - lr: 4.5000e-06\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 7.7855e-04 - lr: 1.3500e-06\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 7.8097e-04 - lr: 1.3500e-06\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 7.8405e-04 - lr: 1.3500e-06\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 7.7327e-04 - lr: 1.3500e-06\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 7.8219e-04 - lr: 1.3500e-06\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 7.8205e-04\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 4.0499998021914507e-07.\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 7.8205e-04 - lr: 1.3500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 12)\n",
      "(4608, 12)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0009\n",
      "rmse: 0.0307\n",
      "mae: 0.0216\n",
      "mape:  0.0904\n",
      "r2: 0.9682\n",
      "--------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------\n",
      "mse_inv: 191.6538\n",
      "rmse_inv: 13.8439\n",
      "mae_inv: 9.7251\n",
      "mape_inv:  0.0254\n",
      "r2_inv: 0.9682\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'mape: {mape: .4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)\n",
    "\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "mse_inv = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse_inv = math.sqrt(mse_inv)\n",
    "mae_inv = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mape_inv = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "r2_inv = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse_inv: {mse_inv:.4f}')\n",
    "print(f'rmse_inv: {rmse_inv:.4f}')\n",
    "print(f'mae_inv: {mae_inv:.4f}')\n",
    "print(f'mape_inv: {mape_inv: .4f}')\n",
    "print(f'r2_inv: {r2_inv:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_per_steps(true_values, predicted_values):\n",
    "    n_steps = true_values.shape[1]\n",
    "\n",
    "    mse = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    mape = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        true_step = true_values[:, i]\n",
    "        predicted_step = predicted_values[:, i]\n",
    "\n",
    "        mse_step = mean_squared_error(true_step, predicted_step)\n",
    "        rmse_step = np.sqrt(mse_step)\n",
    "        mae_step = mean_absolute_error(true_step, predicted_step)\n",
    "        mape_step = mean_absolute_percentage_error(true_step, predicted_step)\n",
    "\n",
    "        mse.append(mse_step)\n",
    "        rmse.append(rmse_step)\n",
    "        mae.append(mae_step)\n",
    "        mape.append(mape_step)\n",
    "\n",
    "    return np.array(mse), np.array(rmse), np.array(mae), np.array(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/PhaCIA_TCNs_12steps.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
