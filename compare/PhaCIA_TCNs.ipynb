{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 08:59:38.577001: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 08:59:38.596633: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 08:59:38.596654: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 08:59:38.596667: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 08:59:38.600730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from keras import layers, models, activations\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.saving import register_keras_serializable\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 08:59:39.633378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 08:59:39.633505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 08:59:39.636378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 08:59:39.636509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 08:59:39.636590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 08:59:39.636667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# print(tf.__version__)\n",
    "# print(tf.config.list_physical_devices())\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#   except RuntimeError as e:\n",
    "#     print(e)\n",
    "\n",
    "# CPU config\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "TEST_PLOT_DIR = \"./result/PhaCIA_TCNs/\"\n",
    "load_col = 'out.site_energy.total.energy_consumption.kwh'\n",
    "# MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data[load_col] = data[load_col] * 4 / 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[load_col].to_numpy().reshape(-1, 1))\n",
    "data[load_col] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upgrade</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>models_used</th>\n",
       "      <th>floor_area_represented</th>\n",
       "      <th>out.district_cooling.cooling.energy_consumption.kwh</th>\n",
       "      <th>out.district_heating.heating.energy_consumption.kwh</th>\n",
       "      <th>out.district_heating.water_systems.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.cooling.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.exterior_lighting.energy_consumption.kwh</th>\n",
       "      <th>out.electricity.fans.energy_consumption.kwh</th>\n",
       "      <th>...</th>\n",
       "      <th>out.electricity.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.natural_gas.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.district_heating.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.natural_gas.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.cooling.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.heating.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.interior_equipment.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.total.energy_consumption.kwh.savings</th>\n",
       "      <th>out.other_fuel.water_systems.energy_consumption.kwh.savings</th>\n",
       "      <th>out.site_energy.total.energy_consumption.kwh.savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>3.504000e+04</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.0</td>\n",
       "      <td>35040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-07-02 12:07:30</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>351.077590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10702.802560</td>\n",
       "      <td>3606.591142</td>\n",
       "      <td>20721.475338</td>\n",
       "      <td>...</td>\n",
       "      <td>4979.811962</td>\n",
       "      <td>23848.451624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28859.420341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.378723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16646.463233</td>\n",
       "      <td>...</td>\n",
       "      <td>-28508.867274</td>\n",
       "      <td>262.091277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3108.391514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-04-02 06:11:15</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>56.488275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2706.386049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19725.608356</td>\n",
       "      <td>...</td>\n",
       "      <td>-529.918116</td>\n",
       "      <td>8719.805585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17223.696432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-07-02 12:07:30</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>259.402965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7965.151518</td>\n",
       "      <td>3546.633502</td>\n",
       "      <td>20458.531255</td>\n",
       "      <td>...</td>\n",
       "      <td>2273.919309</td>\n",
       "      <td>18191.504378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23244.709423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-10-01 18:03:45</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>574.228447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15479.805245</td>\n",
       "      <td>7127.583771</td>\n",
       "      <td>21985.597167</td>\n",
       "      <td>...</td>\n",
       "      <td>9286.504567</td>\n",
       "      <td>32494.864830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35158.530405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2.933235e+08</td>\n",
       "      <td>1559.617664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55401.017935</td>\n",
       "      <td>7361.098134</td>\n",
       "      <td>24359.717506</td>\n",
       "      <td>...</td>\n",
       "      <td>40740.822629</td>\n",
       "      <td>159204.018407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136399.915739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.960550e-08</td>\n",
       "      <td>331.710202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898.426784</td>\n",
       "      <td>3564.157927</td>\n",
       "      <td>1548.734876</td>\n",
       "      <td>...</td>\n",
       "      <td>8136.228348</td>\n",
       "      <td>20711.247693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17025.161426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       upgrade            timestamp  models_used  floor_area_represented  \\\n",
       "count  35040.0                35040      35040.0            3.504000e+04   \n",
       "mean      18.0  2018-07-02 12:07:30        535.0            2.933235e+08   \n",
       "min       18.0  2018-01-01 00:15:00        535.0            2.933235e+08   \n",
       "25%       18.0  2018-04-02 06:11:15        535.0            2.933235e+08   \n",
       "50%       18.0  2018-07-02 12:07:30        535.0            2.933235e+08   \n",
       "75%       18.0  2018-10-01 18:03:45        535.0            2.933235e+08   \n",
       "max       18.0  2019-01-01 00:00:00        535.0            2.933235e+08   \n",
       "std        0.0                  NaN          0.0            5.960550e-08   \n",
       "\n",
       "       out.district_cooling.cooling.energy_consumption.kwh  \\\n",
       "count                                       35040.000000     \n",
       "mean                                          351.077590     \n",
       "min                                             0.000000     \n",
       "25%                                            56.488275     \n",
       "50%                                           259.402965     \n",
       "75%                                           574.228447     \n",
       "max                                          1559.617664     \n",
       "std                                           331.710202     \n",
       "\n",
       "       out.district_heating.heating.energy_consumption.kwh  \\\n",
       "count                                            35040.0     \n",
       "mean                                                 0.0     \n",
       "min                                                  0.0     \n",
       "25%                                                  0.0     \n",
       "50%                                                  0.0     \n",
       "75%                                                  0.0     \n",
       "max                                                  0.0     \n",
       "std                                                  0.0     \n",
       "\n",
       "       out.district_heating.water_systems.energy_consumption.kwh  \\\n",
       "count                                            35040.0           \n",
       "mean                                                 0.0           \n",
       "min                                                  0.0           \n",
       "25%                                                  0.0           \n",
       "50%                                                  0.0           \n",
       "75%                                                  0.0           \n",
       "max                                                  0.0           \n",
       "std                                                  0.0           \n",
       "\n",
       "       out.electricity.cooling.energy_consumption.kwh  \\\n",
       "count                                    35040.000000   \n",
       "mean                                     10702.802560   \n",
       "min                                        326.378723   \n",
       "25%                                       2706.386049   \n",
       "50%                                       7965.151518   \n",
       "75%                                      15479.805245   \n",
       "max                                      55401.017935   \n",
       "std                                       9898.426784   \n",
       "\n",
       "       out.electricity.exterior_lighting.energy_consumption.kwh  \\\n",
       "count                                       35040.000000          \n",
       "mean                                         3606.591142          \n",
       "min                                             0.000000          \n",
       "25%                                             0.000000          \n",
       "50%                                          3546.633502          \n",
       "75%                                          7127.583771          \n",
       "max                                          7361.098134          \n",
       "std                                          3564.157927          \n",
       "\n",
       "       out.electricity.fans.energy_consumption.kwh  ...  \\\n",
       "count                                 35040.000000  ...   \n",
       "mean                                  20721.475338  ...   \n",
       "min                                   16646.463233  ...   \n",
       "25%                                   19725.608356  ...   \n",
       "50%                                   20458.531255  ...   \n",
       "75%                                   21985.597167  ...   \n",
       "max                                   24359.717506  ...   \n",
       "std                                    1548.734876  ...   \n",
       "\n",
       "       out.electricity.total.energy_consumption.kwh.savings  \\\n",
       "count                                       35040.000000      \n",
       "mean                                         4979.811962      \n",
       "min                                        -28508.867274      \n",
       "25%                                          -529.918116      \n",
       "50%                                          2273.919309      \n",
       "75%                                          9286.504567      \n",
       "max                                         40740.822629      \n",
       "std                                          8136.228348      \n",
       "\n",
       "       out.natural_gas.total.energy_consumption.kwh.savings  \\\n",
       "count                                       35040.000000      \n",
       "mean                                        23848.451624      \n",
       "min                                           262.091277      \n",
       "25%                                          8719.805585      \n",
       "50%                                         18191.504378      \n",
       "75%                                         32494.864830      \n",
       "max                                        159204.018407      \n",
       "std                                         20711.247693      \n",
       "\n",
       "       out.district_heating.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0             \n",
       "mean                                                 0.0             \n",
       "min                                                  0.0             \n",
       "25%                                                  0.0             \n",
       "50%                                                  0.0             \n",
       "75%                                                  0.0             \n",
       "max                                                  0.0             \n",
       "std                                                  0.0             \n",
       "\n",
       "       out.natural_gas.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0        \n",
       "mean                                                 0.0        \n",
       "min                                                  0.0        \n",
       "25%                                                  0.0        \n",
       "50%                                                  0.0        \n",
       "75%                                                  0.0        \n",
       "max                                                  0.0        \n",
       "std                                                  0.0        \n",
       "\n",
       "       out.other_fuel.cooling.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0       \n",
       "mean                                                 0.0       \n",
       "min                                                  0.0       \n",
       "25%                                                  0.0       \n",
       "50%                                                  0.0       \n",
       "75%                                                  0.0       \n",
       "max                                                  0.0       \n",
       "std                                                  0.0       \n",
       "\n",
       "       out.other_fuel.heating.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0       \n",
       "mean                                                 0.0       \n",
       "min                                                  0.0       \n",
       "25%                                                  0.0       \n",
       "50%                                                  0.0       \n",
       "75%                                                  0.0       \n",
       "max                                                  0.0       \n",
       "std                                                  0.0       \n",
       "\n",
       "       out.other_fuel.interior_equipment.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0                  \n",
       "mean                                                 0.0                  \n",
       "min                                                  0.0                  \n",
       "25%                                                  0.0                  \n",
       "50%                                                  0.0                  \n",
       "75%                                                  0.0                  \n",
       "max                                                  0.0                  \n",
       "std                                                  0.0                  \n",
       "\n",
       "       out.other_fuel.total.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0     \n",
       "mean                                                 0.0     \n",
       "min                                                  0.0     \n",
       "25%                                                  0.0     \n",
       "50%                                                  0.0     \n",
       "75%                                                  0.0     \n",
       "max                                                  0.0     \n",
       "std                                                  0.0     \n",
       "\n",
       "       out.other_fuel.water_systems.energy_consumption.kwh.savings  \\\n",
       "count                                            35040.0             \n",
       "mean                                                 0.0             \n",
       "min                                                  0.0             \n",
       "25%                                                  0.0             \n",
       "50%                                                  0.0             \n",
       "75%                                                  0.0             \n",
       "max                                                  0.0             \n",
       "std                                                  0.0             \n",
       "\n",
       "       out.site_energy.total.energy_consumption.kwh.savings  \n",
       "count                                       35040.000000     \n",
       "mean                                        28859.420341     \n",
       "min                                          3108.391514     \n",
       "25%                                         17223.696432     \n",
       "50%                                         23244.709423     \n",
       "75%                                         35158.530405     \n",
       "max                                        136399.915739     \n",
       "std                                         17025.161426     \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a list of timestamps every 2 hours within the dataset's range\n",
    "def generate_timestamps(data) -> pd.DatetimeIndex:\n",
    "    start = data['timestamp'].min() + DateOffset(days=3)\n",
    "    end = data['timestamp'].max() - DateOffset(minutes=96*15)\n",
    "    timestamps = pd.date_range(start=start, end=end, freq='15min')\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-01-04 00:15:00', '2018-01-04 00:30:00',\n",
      "               '2018-01-04 00:45:00', '2018-01-04 01:00:00',\n",
      "               '2018-01-04 01:15:00', '2018-01-04 01:30:00',\n",
      "               '2018-01-04 01:45:00', '2018-01-04 02:00:00',\n",
      "               '2018-01-04 02:15:00', '2018-01-04 02:30:00',\n",
      "               ...\n",
      "               '2018-12-30 21:45:00', '2018-12-30 22:00:00',\n",
      "               '2018-12-30 22:15:00', '2018-12-30 22:30:00',\n",
      "               '2018-12-30 22:45:00', '2018-12-30 23:00:00',\n",
      "               '2018-12-30 23:15:00', '2018-12-30 23:30:00',\n",
      "               '2018-12-30 23:45:00', '2018-12-31 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=34656, freq='15min')\n"
     ]
    }
   ],
   "source": [
    "timestamps = generate_timestamps(data)\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sets_for_all_timestamps(timestamps, data):\n",
    "    training_sets = []\n",
    "    change_rate_sets = []\n",
    "    target_sets = []\n",
    "    training_sets_time = []\n",
    "    target_sets_time = []\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        # Calculate the range for the current period's data\n",
    "        start_time_current = timestamp - DateOffset(days=2, hours=23, minutes=45)\n",
    "        end_time_current = timestamp\n",
    "\n",
    "        # Calculate the target range (the next 10 steps after the current timestamp)\n",
    "        target_start_time = timestamp + DateOffset(minutes=15)\n",
    "        target_end_time = timestamp + DateOffset(hours=0, minutes=96*15) \n",
    "\n",
    "        # Filter the data for training and target sets\n",
    "        current_data = data[(data['timestamp'] >= start_time_current) & (data['timestamp'] <= end_time_current)]\n",
    "        target_data = data[(data['timestamp'] >= target_start_time) & (data['timestamp'] <= target_end_time)]\n",
    "\n",
    "        # Combine current and last week data for the training set\n",
    "        training_data = pd.concat([current_data]).reset_index(drop=True)\n",
    "        \n",
    "        # Save the training and target sets\n",
    "        if not training_data.empty and not target_data.empty:\n",
    "            training_sets.append(training_data[load_col])\n",
    "            target_sets.append(target_data[load_col])\n",
    "            training_sets_time.append(list(training_data['timestamp']))\n",
    "            target_sets_time.append(list(target_data['timestamp']))\n",
    "\n",
    "    training_sets = np.array(training_sets)\n",
    "    target_sets = np.array(target_sets)\n",
    "    training_sets_time = np.array(training_sets_time)\n",
    "    target_sets_time = np.array(target_sets_time)\n",
    "\n",
    "    return training_sets, target_sets, training_sets_time, target_sets_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and target sets for all the timestamps\n",
    "training_sets, target_sets, training_sets_time, target_sets_time = generate_sets_for_all_timestamps(timestamps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(timestamps.shape[0] / 24)\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_test_time = []\n",
    "y_test_time = []\n",
    "minList = []\n",
    "maxList = []\n",
    "for i in range(0, 24):\n",
    "    min = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    max = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test.append(training_sets[min:max])\n",
    "    y_test.append(target_sets[min:max])\n",
    "    X_test_time.append(training_sets_time[min:max])\n",
    "    y_test_time.append(target_sets_time[min:max])\n",
    "    training_sets = np.concatenate([training_sets[:min], training_sets[max:]])\n",
    "    target_sets = np.concatenate([target_sets[:min], target_sets[max:]])\n",
    "    training_sets_time = np.concatenate([training_sets_time[:min], training_sets_time[max:]])\n",
    "    target_sets_time = np.concatenate([target_sets_time[:min], target_sets_time[max:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([i for i in X_test])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_time = np.concatenate([i for i in X_test_time])\n",
    "y_test_time = np.concatenate([i for i in y_test_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_sets.reshape(*training_sets.shape, 1)\n",
    "X_test = X_test.reshape(*X_test.shape, 1)\n",
    "y_train = target_sets\n",
    "X_train_time = training_sets_time\n",
    "y_train_time = target_sets_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 288, 1)\n",
      "(4608, 288, 1)\n",
      "(30048, 96)\n",
      "(4608, 96)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_test).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IA Module\n",
    "@register_keras_serializable('InputAttention')\n",
    "class InputAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(InputAttention, self).__init__()\n",
    "        self.linear = layers.Dense(1, activation=None)\n",
    "        self.relu = layers.Dense(1, activation='relu')\n",
    "        self.tanh = layers.Dense(1, activation='tanh')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_output = self.linear(inputs)\n",
    "        relu_output = self.relu(linear_output + inputs)\n",
    "        tanh_output = self.tanh(relu_output + inputs)\n",
    "        attention_weights = tf.nn.softmax(tanh_output, axis=1)\n",
    "        weighted_inputs = inputs * attention_weights\n",
    "        return weighted_inputs\n",
    "\n",
    "# PhaC module\n",
    "@register_keras_serializable('ParallelHybridActivatedConvolution')\n",
    "class ParallelHybridActivatedConvolution(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dilation_rate):\n",
    "        super(ParallelHybridActivatedConvolution, self).__init__()\n",
    "        self.dilated_conv = layers.Conv1D(filters, kernel_size, dilation_rate=dilation_rate, padding='causal')\n",
    "        self.relu = layers.ReLU()\n",
    "        self.tanh = layers.Activation('tanh')\n",
    "        self.conv1x1 = layers.Conv1D(filters, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dilated_conv(inputs)\n",
    "        x_relu = self.relu(x)\n",
    "        x_tanh = self.tanh(x)\n",
    "        x_activated = x_relu * x_tanh\n",
    "        x_residual = self.conv1x1(inputs)\n",
    "        return x_activated + x_residual\n",
    "\n",
    "# PhaCIA-TCNs\n",
    "def build_phacia_tcn(input_shape, filters, kernel_size, dilation_rates, n_predict):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 輸入注意力模塊\n",
    "    x = InputAttention()(inputs)\n",
    "    \n",
    "    # TCN Backbone with PhaC modules\n",
    "    for dilation_rate in dilation_rates:\n",
    "        x = ParallelHybridActivatedConvolution(filters, kernel_size, dilation_rate)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        x = ParallelHybridActivatedConvolution(filters*2, kernel_size, dilation_rate)(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(n_predict*2, activation='linear')(x)\n",
    "    outputs = layers.Dense(n_predict, activation='linear')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [*X_train.shape[1:]]\n",
    "filters = 64\n",
    "kernel_size = 3\n",
    "n_predict = 96\n",
    "dilation_rates = [1, 2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 288, 1)]          0         \n",
      "                                                                 \n",
      " input_attention (InputAtte  (None, 288, 1)            6         \n",
      " ntion)                                                          \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           384       \n",
      " convolution (ParallelHybri                                      \n",
      " dActivatedConvolution)                                          \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_1 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_2 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_3 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 64)           16512     \n",
      " convolution_4 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 288, 64)           256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          33024     \n",
      " convolution_5 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_6 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_7 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_8 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " parallel_hybrid_activated_  (None, 288, 128)          65792     \n",
      " convolution_9 (ParallelHyb                                      \n",
      " ridActivatedConvolution)                                        \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 288, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 192)               7078080   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 96)                18528     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7460006 (28.46 MB)\n",
      "Trainable params: 7459622 (28.46 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = build_phacia_tcn(input_shape, filters, kernel_size, dilation_rates, n_predict)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 09:00:34.604951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7eec088030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-26 09:00:34.604996: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-26 09:00:34.609792: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-26 09:00:34.631250: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-07-26 09:00:34.632289: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2024-07-26 09:00:34.649131: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2024-07-26 09:00:34.761535: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 54s 164ms/step - loss: 0.0181 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 0.0067 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "267/313 [========================>.....] - ETA: 7s - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 09:02:57.866157: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 50s 159ms/step - loss: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 0.0049 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "  8/313 [..............................] - ETA: 50s - loss: 0.0030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 09:10:43.197260: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 51s 163ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 52s 165ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 52s 165ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 52s 166ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 52s 165ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 0.0026 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 49s 155ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0019\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "313/313 [==============================] - 48s 155ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 50s 158ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0016 - lr: 1.5000e-05\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0017\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0015 - lr: 4.5000e-06\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0015\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0015 - lr: 4.5000e-06\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0015\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 4.0499998021914507e-07.\n",
      "313/313 [==============================] - 48s 155ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 49s 155ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 50s 158ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0015\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.2149999406574352e-07.\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0015 - lr: 1.2150e-07\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0015 - lr: 1.2150e-07\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.0015 - lr: 1.2150e-07\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 0.0015 - lr: 1.2150e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 3s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 96)\n",
      "(4608, 96)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0021\n",
      "rmse: 0.0454\n",
      "mae: 0.0335\n",
      "mape:  0.1270\n",
      "r2: 0.9316\n",
      "--------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------\n",
      "mse_inv: 418.9724\n",
      "rmse_inv: 20.4688\n",
      "mae_inv: 15.1220\n",
      "mape_inv:  0.0381\n",
      "r2_inv: 0.9316\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'mape: {mape: .4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)\n",
    "\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "mse_inv = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse_inv = math.sqrt(mse_inv)\n",
    "mae_inv = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mape_inv = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "r2_inv = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse_inv: {mse_inv:.4f}')\n",
    "print(f'rmse_inv: {rmse_inv:.4f}')\n",
    "print(f'mae_inv: {mae_inv:.4f}')\n",
    "print(f'mape_inv: {mape_inv: .4f}')\n",
    "print(f'r2_inv: {r2_inv:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_per_steps(true_values, predicted_values):\n",
    "    n_steps = true_values.shape[1]\n",
    "\n",
    "    mse = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    mape = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        true_step = true_values[:, i]\n",
    "        predicted_step = predicted_values[:, i]\n",
    "\n",
    "        mse_step = mean_squared_error(true_step, predicted_step)\n",
    "        rmse_step = np.sqrt(mse_step)\n",
    "        mae_step = mean_absolute_error(true_step, predicted_step)\n",
    "        mape_step = mean_absolute_percentage_error(true_step, predicted_step)\n",
    "\n",
    "        mse.append(mse_step)\n",
    "        rmse.append(rmse_step)\n",
    "        mae.append(mae_step)\n",
    "        mape.append(mape_step)\n",
    "\n",
    "    return np.array(mse), np.array(rmse), np.array(mae), np.array(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/PhaCIA_TCNs_96steps.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = \"./result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(y_pred)\n",
    "result_df.to_csv(RESULT_DIR+\"PhaCIA_TCN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
