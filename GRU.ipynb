{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Conv1D, GRU, Attention\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "TEST_PLOT_DIR = \"./test_plots/GRU/\"\n",
    "MODEL_FILE_DIR = \"./model/GRU.keras\"\n",
    "TRAINING_HISTORY_DIR = \"./training_history/GRU.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "PREDICT_STEP = 16\n",
    "INPUT_STEP = 192\n",
    "\n",
    "N_FEATURE = 1\n",
    "N_OUPUT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into train, validation, and test sets\n",
    "def split_data(df, train_frac=0.75, test_frac=0.15):\n",
    "    # Sort data by year_month\n",
    "    grouped = df.groupby('year_month')\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "\n",
    "    for name, group in grouped:\n",
    "        n = len(group)\n",
    "        train_end = int(train_frac * n)\n",
    "        test_end = train_end + int(test_frac * n)   \n",
    "        train_data = pd.concat([train_data, group.iloc[:train_end]], ignore_index=True)\n",
    "        val_data = pd.concat([val_data, group.iloc[train_end:test_end]], ignore_index=True)\n",
    "        test_data = pd.concat([test_data, group.iloc[test_end:]], ignore_index=True)\n",
    "    # adding time_idx\n",
    "    train_data['time_idx'] = np.arange(len(train_data))\n",
    "    test_data['time_idx'] = np.arange(len(test_data))\n",
    "    val_data['time_idx'] = np.arange(len(val_data))\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back, look_forward):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-look_forward+1):\n",
    "        X = dataset[i:(i+look_back), :]\n",
    "        y = dataset[(i+look_back):(i+look_back+look_forward), 0]\n",
    "        dataX.append(X)\n",
    "        dataY.append(y)\n",
    "    return np.array(dataX), np.array(dataY).reshape(np.array(dataY).shape[0], np.array(dataY).shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "# Convert the 'date' column to datetime format\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Sort the data by date\n",
    "data.sort_values('Timestamp', inplace=True)\n",
    "\n",
    "# Extract month and year from the date for splitting\n",
    "data['year_month'] = data['Timestamp'].dt.to_period('M')\n",
    "\n",
    "# Splitting the data\n",
    "train_df, test_df, val_df = split_data(data)\n",
    "\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(data[\"Load\"]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "      <th>year_month</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>10.89</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>10.44</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>10.89</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "      <td>10.29</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>10.34</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26275</th>\n",
       "      <td>2023-12-24 04:45:00</td>\n",
       "      <td>8.96</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>26275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26276</th>\n",
       "      <td>2023-12-24 05:00:00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>26276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26277</th>\n",
       "      <td>2023-12-24 05:15:00</td>\n",
       "      <td>8.81</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>26277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26278</th>\n",
       "      <td>2023-12-24 05:30:00</td>\n",
       "      <td>10.25</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>26278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26279</th>\n",
       "      <td>2023-12-24 05:45:00</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>26279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp   Load year_month  time_idx\n",
       "0     2023-01-01 00:00:00  10.89    2023-01         0\n",
       "1     2023-01-01 00:15:00  10.44    2023-01         1\n",
       "2     2023-01-01 00:30:00  10.89    2023-01         2\n",
       "3     2023-01-01 00:45:00  10.29    2023-01         3\n",
       "4     2023-01-01 01:00:00  10.34    2023-01         4\n",
       "...                   ...    ...        ...       ...\n",
       "26275 2023-12-24 04:45:00   8.96    2023-12     26275\n",
       "26276 2023-12-24 05:00:00   6.90    2023-12     26276\n",
       "26277 2023-12-24 05:15:00   8.81    2023-12     26277\n",
       "26278 2023-12-24 05:30:00  10.25    2023-12     26278\n",
       "26279 2023-12-24 05:45:00   8.16    2023-12     26279\n",
       "\n",
       "[26280 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(scaler.transform(np.array(train_df['Load']).reshape(-1, 1)), INPUT_STEP, PREDICT_STEP)\n",
    "X_val, y_val = create_dataset(scaler.transform(np.array(val_df['Load']).reshape(-1, 1)), INPUT_STEP, PREDICT_STEP)\n",
    "X_test, y_test = create_dataset(scaler.transform(np.array(test_df['Load']).reshape(-1, 1)), INPUT_STEP, PREDICT_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "X_train: (26073, 192, 1)\n",
      "y_train: (26073, 16, 1)\n",
      "X_val: (5046, 192, 1)\n",
      "y_val: (5046, 16, 1)\n",
      "X_test: (3300, 192, 1)\n",
      "y_test: (3300, 16, 1)\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 86)\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 16:18:56.418026: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-01-18 16:18:56.418051: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-18 16:18:56.418061: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-18 16:18:56.418093: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-18 16:18:56.418109: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 192, 50)           7950      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 25)                5775      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                1300      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                816       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15841 (61.88 KB)\n",
      "Trainable params: 15841 (61.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 16:18:57.365433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/105 [..............................] - ETA: 1:33:26 - loss: 0.1555"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, activation='relu', return_sequences=True, input_shape=(INPUT_STEP, N_FEATURE)))\n",
    "    model.add(GRU(25, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(PREDICT_STEP))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        min_delta=0.0001,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=1,\n",
    "        epochs=100,\n",
    "        batch_size=250,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "# plot loss & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(TRAINING_HISTORY_DIR)\n",
    "plt.close()\n",
    "\n",
    "model.save(MODEL_FILE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model = load_model(MODEL_FILE_DIR)\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(\"-\" * 86)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "X_test_reshaped = X_test[:, :, 0]\n",
    "y_test_reshaped = np.reshape(y_test, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "pred_data = np.concatenate(\n",
    "    [scaler.inverse_transform(X_test_reshaped),\n",
    "        scaler.inverse_transform(pred)],\n",
    "    axis=-1\n",
    ")\n",
    "actual_data = np.concatenate(\n",
    "    [scaler.inverse_transform(X_test_reshaped),\n",
    "        scaler.inverse_transform(y_test_reshaped)],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "for i in range(actual_data.shape[0]):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    X = np.arange(1, actual_data.shape[1]+1, 1)\n",
    "    y_pred = pred_data[i]\n",
    "    y_actual = actual_data[i]\n",
    "    plt.title(f\"Time Series {i+1} prediction result\")\n",
    "    plt.plot(X, y_pred, label='Predict')\n",
    "    plt.plot(X, y_actual, label='Actual')\n",
    "    plt.ylim(0, 30)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
