{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, LSTM, Conv1D, Input, Attention\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\"\n",
    "TEST_PLOT_DIR = \"./test_plots/CNN_LSTM/\"\n",
    "MODEL_FILE_DIR = \"./model/CNN_LSTM.keras\"\n",
    "TRAINING_HISTORY_DIR = \"./training_history/CNN_LSTM.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "PREDICT_STEP = 16\n",
    "INPUT_STEP = 192\n",
    "\n",
    "N_FEATURE = 1\n",
    "N_OUPUT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into train, validation, and test sets\n",
    "def split_data(df, train_frac=0.75, test_frac=0.15):\n",
    "    # Sort data by year_month\n",
    "    grouped = df.groupby('year_month')\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "\n",
    "    for name, group in grouped:\n",
    "        n = len(group)\n",
    "        train_end = int(train_frac * n)\n",
    "        test_end = train_end + int(test_frac * n)   \n",
    "        train_data = pd.concat([train_data, group.iloc[:train_end]], ignore_index=True)\n",
    "        val_data = pd.concat([val_data, group.iloc[train_end:test_end]], ignore_index=True)\n",
    "        test_data = pd.concat([test_data, group.iloc[test_end:]], ignore_index=True)\n",
    "    # adding time_idx\n",
    "    train_data['time_idx'] = np.arange(len(train_data))\n",
    "    test_data['time_idx'] = np.arange(len(test_data))\n",
    "    val_data['time_idx'] = np.arange(len(val_data))\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back, look_forward):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-look_forward+1):\n",
    "        X = dataset[i:(i+look_back), :]\n",
    "        y = dataset[(i+look_back):(i+look_back+look_forward), 0]\n",
    "        dataX.append(X)\n",
    "        dataY.append(y)\n",
    "    return np.array(dataX), np.array(dataY).reshape(np.array(dataY).shape[0], np.array(dataY).shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "# Convert the 'date' column to datetime format\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Sort the data by date\n",
    "data.sort_values('Timestamp', inplace=True)\n",
    "\n",
    "# Extract month and year from the date for splitting\n",
    "data['year_month'] = data['Timestamp'].dt.to_period('M')\n",
    "\n",
    "# Splitting the data\n",
    "train_df, test_df, val_df = split_data(data)\n",
    "\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(data[\"Load\"]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(scaler.transform(np.array(train_df['Load']).reshape(-1, 1)), INPUT_STEP, PREDICT_STEP)\n",
    "X_val, y_val = create_dataset(scaler.transform(np.array(val_df['Load']).reshape(-1, 1)), INPUT_STEP, PREDICT_STEP)\n",
    "X_test, y_test = create_dataset(scaler.transform(np.array(test_df['Load']).reshape(-1, 1)), INPUT_STEP, PREDICT_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 86)\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    inputs = Input(shape=(INPUT_STEP, N_FEATURE))\n",
    "    conv = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    encoder = LSTM(64, return_sequences=True)(conv)\n",
    "    # decoder_inputs = Attention()([encoder, encoder])\n",
    "    decoder = LSTM(64, return_sequences=False)(encoder)\n",
    "    dense1 = Dense(50, activation='relu')(decoder)\n",
    "    dense2 = Dense(PREDICT_STEP)(dense1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=dense2)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        min_delta=0.0001,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=1,\n",
    "        epochs=100,\n",
    "        batch_size=250,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "# plot loss & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(TRAINING_HISTORY_DIR)\n",
    "plt.close()\n",
    "\n",
    "model.save(MODEL_FILE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model = load_model(MODEL_FILE_DIR)\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(\"-\" * 86)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "X_test_reshaped = X_test[:, :, 0]\n",
    "y_test_reshaped = np.reshape(y_test, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "pred_data = np.concatenate(\n",
    "    [scaler.inverse_transform(X_test_reshaped),\n",
    "        scaler.inverse_transform(pred)],\n",
    "    axis=-1\n",
    ")\n",
    "actual_data = np.concatenate(\n",
    "    [scaler.inverse_transform(X_test_reshaped),\n",
    "        scaler.inverse_transform(y_test_reshaped)],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "for i in range(actual_data.shape[0]):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    X = np.arange(1, actual_data.shape[1]+1, 1)\n",
    "    y_pred = pred_data[i]\n",
    "    y_actual = actual_data[i]\n",
    "    plt.title(f\"Time Series {i+1} prediction result\")\n",
    "    plt.plot(X, y_pred, label='Predict')\n",
    "    plt.plot(X, y_actual, label='Actual')\n",
    "    plt.ylim(0, 30)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
