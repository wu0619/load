{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 05:54:03.148404: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-09 05:54:03.166807: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-09 05:54:03.166821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-09 05:54:03.166836: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-09 05:54:03.170842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse.linalg import cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 05:54:04.285066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.285205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.288798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.288922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.289004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.289083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.290559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.290664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.290736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.342118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.342223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.342299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 05:54:04.342363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset columns must be the format below:\\n\\n  index             Timestamp   Load\\n      0   20xx-xx-xx xx:xx:xx    xxx\\n      1                   ...    ...\\n      2                   ...    ...\\n                                 ...\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset columns must be the format below:\n",
    "\n",
    "  index             Timestamp   Load\n",
    "      0   20xx-xx-xx xx:xx:xx    xxx\n",
    "      1                   ...    ...\n",
    "      2                   ...    ...\n",
    "                                 ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>0.427049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "      <td>0.420902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>0.422951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>2023-12-31 22:45:00</td>\n",
       "      <td>0.331148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>0.270492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>2023-12-31 23:15:00</td>\n",
       "      <td>0.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>2023-12-31 23:30:00</td>\n",
       "      <td>0.337295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>2023-12-31 23:45:00</td>\n",
       "      <td>0.253689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp      Load\n",
       "0     2023-01-01 00:00:00  0.445492\n",
       "1     2023-01-01 00:15:00  0.427049\n",
       "2     2023-01-01 00:30:00  0.445492\n",
       "3     2023-01-01 00:45:00  0.420902\n",
       "4     2023-01-01 01:00:00  0.422951\n",
       "...                   ...       ...\n",
       "35035 2023-12-31 22:45:00  0.331148\n",
       "35036 2023-12-31 23:00:00  0.270492\n",
       "35037 2023-12-31 23:15:00  0.365574\n",
       "35038 2023-12-31 23:30:00  0.337295\n",
       "35039 2023-12-31 23:45:00  0.253689\n",
       "\n",
       "[35040 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 96\n",
    "height = 4\n",
    "width = 24\n",
    "n_days_b = 3\n",
    "n_days_s = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageEncoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days_b: int,\n",
    "        n_days_s: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days_b\n",
    "        self.d_s = n_days_s\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['Timestamp'].min() + DateOffset(days=self.d_b)\n",
    "        end = self.X['Timestamp'].max() - DateOffset(minutes=self.n_predict*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def generate_gaussian_noise(self, length, std_dev=0.15):\n",
    "        noise = np.random.normal(loc=0.5, scale=std_dev, size=length)\n",
    "        noise = np.clip(noise, 0, 1)\n",
    "        # noise = np.zeros(shape=length)\n",
    "        return pd.DataFrame({\"Load\": noise})\n",
    "    \n",
    "    def make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            # noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start_b) & (self.X['Timestamp'] <= training_end)]\n",
    "            # training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            target_data = self.X[(self.X['Timestamp'] >= target_start) & (self.X['Timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data['Load'])\n",
    "                self.X_timestamp.append(training_data['Timestamp'])\n",
    "                self.y_timestamp.append(target_data['Timestamp'])\n",
    "                training_reshaped = np.array(training_data['Load']).reshape(self.d_b, self.h, self.m)\n",
    "                symmetric_3d = self.make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(symmetric_3d)\n",
    "                target_reshaped = np.array(target_data['Load']).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                symmetric_2d = self.make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(symmetric_2d)\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    # def encode_s(self):\n",
    "    #     training_sets = []\n",
    "    #     for steps in self.timestamps:\n",
    "    #         training_subset = []\n",
    "    #         point = steps - DateOffset(days=self.d_s-1)\n",
    "    #         training_start = point - DateOffset(minutes=(self.m-1)*15)\n",
    "    #         # training\n",
    "    #         for _ in range(self.d_s-1):\n",
    "    #             training_end = training_start + DateOffset(minutes=(self.m-1)*15)\n",
    "    #             training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "    #             if not training_data.empty:\n",
    "    #                 symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "    #                 training_subset.append(symmetric_2d)\n",
    "    #             training_start = training_start + DateOffset(days=1)\n",
    "    #         training_end = training_start + DateOffset(minutes=(self.m-self.n_predict-1)*15)\n",
    "    #         training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "    #         noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "    #         training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "    #         symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "    #         training_subset.append(symmetric_2d)\n",
    "    #         training_sets.append(training_subset)\n",
    "    #     training_sets = np.array(training_sets)\n",
    "    #     return training_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 96\n",
      "Ls: 96\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageEncoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days_b=n_days_b,\n",
    "    n_days_s=n_days_s,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34656, 8, 24, 3)\n",
      "(34656, 8, 24)\n",
      "(34656, 288)\n",
      "(34656, 288)\n",
      "(34656, 96)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 8, 24, 3)\n",
      "(4608, 8, 24, 3)\n",
      "(30048, 8, 24)\n",
      "(4608, 8, 24)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 96)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('ECALayer')\n",
    "class ECALayer(Layer):\n",
    "    def __init__(self, gamma=2, b=1, **kwargs):\n",
    "        super(ECALayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.t = max(1, int(abs((tf.math.log(float(c)) / tf.math.log(2.0) + self.b) / self.gamma)))\n",
    "        self.conv = Conv1D(filters=1, kernel_size=self.t, padding='same', use_bias=False)\n",
    "        super(ECALayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Global Average Pooling over the spatial dimensions to produce a (batch_size, 1, channels) tensor\n",
    "        x = GlobalAveragePooling2D()(inputs)\n",
    "        x = Reshape((1, -1))(x)\n",
    "        x = self.conv(x)\n",
    "        x = sigmoid(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeeze to make it (batch_size, channels)\n",
    "        \n",
    "        # Multiply weights across channels\n",
    "        return inputs * x[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ECALayer, self).get_config()\n",
    "        config.update({\n",
    "            'gamma': self.gamma,\n",
    "            'b': self.b\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('AverageLayer')\n",
    "class AverageLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AverageLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs[0] + inputs[1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_shape_b, input_shape_s, num_outputs):\n",
    "#     inputs_b = Input(shape=input_shape_b)\n",
    "#     inputs_s = Input(shape=input_shape_s)\n",
    "#     conv1 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "#     conv2 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "#     conv2 = Reshape((1, *conv2.shape[1:]))(conv2)  \n",
    "#     lstm1 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv2)\n",
    "#     lstm2 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm1)\n",
    "#     eca1 = ECALayer()(lstm2)\n",
    "#     conv3 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(eca1)\n",
    "#     conv4 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "#     maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(conv4)\n",
    "#     flatten1 = Flatten()(maxpool1)\n",
    "#     dense1 = Dense(2*num_outputs, activation=\"linear\")(flatten1)\n",
    "#     outputs1 = Reshape((2, 12))(dense1)\n",
    "\n",
    "#     conv5 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(inputs_s)\n",
    "#     conv6 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv5)\n",
    "#     conv6 = Reshape((1, *conv6.shape[1:]))(conv6)  \n",
    "#     lstm3 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv6)\n",
    "#     lstm4 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm3)\n",
    "#     eca2 = ECALayer()(lstm4)\n",
    "#     conv7 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(eca2)\n",
    "#     conv8 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv7)\n",
    "#     maxpool2 = MaxPooling2D(pool_size=5, padding=\"same\")(conv8)\n",
    "#     flatten2 = Flatten()(maxpool2)\n",
    "#     dense2 = Dense(2*num_outputs, activation=\"linear\")(flatten2)\n",
    "#     outputs2 = Reshape((2, 12))(dense2)\n",
    "\n",
    "#     final_output = AverageLayer()([outputs1, outputs2])\n",
    "#     model = Model(inputs=[inputs_b, inputs_s], outputs=final_output)\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_b, encoder):\n",
    "    height, width = math.ceil(encoder.n_predict / encoder.m) * 2, min(encoder.n_predict, encoder.m)\n",
    "    inputs_b = Input(shape=input_shape_b)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "    conv2 = Reshape((1, *conv2.shape[1:]))(conv2)\n",
    "    nor1 = BatchNormalization()(conv2)\n",
    "    lstm1 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.0))(nor1)\n",
    "    nor2 = BatchNormalization()(lstm1)\n",
    "    lstm2 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.0))(nor2)\n",
    "    nor3 = BatchNormalization()(lstm2)\n",
    "    eca1 = ECALayer()(nor3)\n",
    "    nor4 = BatchNormalization()(eca1)\n",
    "    conv3 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(nor4)\n",
    "    conv4 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "    nor5 = BatchNormalization()(conv4)\n",
    "    maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(nor5)\n",
    "    flatten1 = Flatten()(maxpool1)\n",
    "    dense1 = Dense(height*width, activation=\"linear\")(flatten1)\n",
    "    outputs = Reshape((height, width))(dense1)\n",
    "    model = Model(inputs=inputs_b, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 24, 3)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 24, 32)         896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 24, 64)         18496     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 8, 24, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 8, 24, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1, 8, 24, 192)     1106688   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 8, 24, 192)     768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 8, 24, 192)        1991424   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " eca_layer (ECALayer)        (None, 8, 24, 192)        768       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 24, 64)         110656    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 24, 32)         18464     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 24, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 3, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               18624     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 8, 24)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3268704 (12.47 MB)\n",
      "Trainable params: 3267360 (12.46 MB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = create_model(input_shape_b=X_train_b.shape[1:], encoder=encoder)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lbfgs(model, loss_fn, x_data, y_data, learning_rate_theta=1e-5):\n",
    "    # flatten model parameters theta to 1-dim array\n",
    "    initial_params = tf.concat([tf.reshape(param, [-1]) for param in model.trainable_variables], axis=0)\n",
    "\n",
    "    # define a function to calculate loss and gradient\n",
    "    def value_and_gradients_function(params):\n",
    "        # update model parameter theta\n",
    "        assign_new_model_parameters(model, params)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_variables)\n",
    "            predictions = model(x_data, training=True)\n",
    "            loss = loss_fn(y_data, predictions)\n",
    "        # calculate the loss gradient w.r.t model parameters theta\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        flat_grads = tf.concat([tf.reshape(grad, [-1]) for grad in grads], axis=0)\n",
    "        return loss, flat_grads\n",
    "\n",
    "    # execute L-BFGS optimization\n",
    "    results = tfp.optimizer.lbfgs_minimize(\n",
    "        value_and_gradients_function,\n",
    "        initial_position=initial_params,\n",
    "        tolerance=1e-8  # adjust to appropriate training tolerance\n",
    "    )\n",
    "\n",
    "    # assign new model parameter theta\n",
    "    assign_new_model_parameters(model, results.position)\n",
    "\n",
    "def assign_new_model_parameters(model, flat_params):\n",
    "    \"\"\" Update model parameter theta \"\"\"\n",
    "    start = 0\n",
    "    for param in model.trainable_variables:\n",
    "        size = tf.size(param)\n",
    "        new_shape = tf.shape(param)\n",
    "        param.assign(tf.reshape(flat_params[start:start + size], new_shape))\n",
    "        start += size\n",
    "\n",
    "def update_weights(model, X_val, y_val, weights, learning_rate_w):\n",
    "    \"\"\" Update the weight of the sample \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(weights)\n",
    "        predictions = model(X_val, training=True)\n",
    "        loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_val[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    new_weights = tf.clip_by_value(weights - learning_rate_w * grads, 1e-5, 1)\n",
    "    return new_weights\n",
    "\n",
    "def training(model, X_train, y_train, X_val, y_val, epochs, batch_size, callbacks):\n",
    "    for callback in callbacks:\n",
    "        callback.set_model(model)\n",
    "        callback.on_train_begin()\n",
    "        \n",
    "    weights = tf.Variable(np.ones(len(X_train)) / len(X_train), dtype=tf.float32)\n",
    "    # learning rate of the sample weight\n",
    "    learning_rate_w = 5e-5\n",
    "    # learning rate of the model parameters θ\n",
    "    learning_rate_theta = 1e-5\n",
    "    # optimizer of model parameters θ\n",
    "    optimizer_theta = Adam(learning_rate=learning_rate_theta)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        for callback in callbacks:\n",
    "            callback.on_epoch_begin(epoch)\n",
    "\n",
    "        for batch in range((len(X_train) + batch_size - 1) // batch_size):\n",
    "            start = batch * batch_size\n",
    "            end = min(start + batch_size, len(X_train))\n",
    "\n",
    "            apply_lbfgs(model, lambda y_true, y_pred: tf.reduce_mean(weights[start:end] * tf.keras.losses.mean_squared_error(y_true[:, 0], tf.reduce_mean(y_pred, axis=1, keepdims=True))), X_train[start:end], y_train[start:end])\n",
    "        \n",
    "        weights.assign(update_weights(model, X_val, y_val, weights, learning_rate_w=learning_rate_w))\n",
    "\n",
    "        predictions = model(X_train, training=True)\n",
    "        val_loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_train[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "        print(f\"val_loss: {val_loss.numpy()}\")\n",
    "        \n",
    "        if early_stopping_callback.stopped_epoch:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    for callback in callbacks:\n",
    "        callback.on_train_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 05:54:28.134837: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/model/bidirectional_1/backward_conv_lstm2d_1/while_grad/body/_948/input/_2185' -> 'gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/model/bidirectional_1/backward_conv_lstm2d_1/while_grad/body/_948/gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/model/bidirectional_1/forward_conv_lstm2d_1/while_grad/body/_753/input/_2066' -> 'gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/model/bidirectional_1/forward_conv_lstm2d_1/while_grad/body/_753/gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional/backward_conv_lstm2d/while/model/bidirectional/backward_conv_lstm2d/while_grad/body/_1338/input/_2423' -> 'gradient_tape/model/bidirectional/backward_conv_lstm2d/while/model/bidirectional/backward_conv_lstm2d/while_grad/body/_1338/gradient_tape/model/bidirectional/backward_conv_lstm2d/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional/forward_conv_lstm2d/while/model/bidirectional/forward_conv_lstm2d/while_grad/body/_1143/input/_2304' -> 'gradient_tape/model/bidirectional/forward_conv_lstm2d/while/model/bidirectional/forward_conv_lstm2d/while_grad/body/_1143/gradient_tape/model/bidirectional/forward_conv_lstm2d/while/gradients/AddN', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_6' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/add_4', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_6' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/add_4', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/clip_by_value' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_3'}.\n",
      "2024-05-09 05:54:28.512974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 21s 57ms/step - loss: 0.2949 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.0400 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 0.0184 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0164 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0154 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0146 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0137 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0128 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0119 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0110 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0103 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0096 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0091 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0086 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0082 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0079 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0076 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0074 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0071 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0069 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0067 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0066 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0064 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0062 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.0061 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0052 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0051 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0049 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0048 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0046 - lr: 5.0000e-05\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0026 - lr: 1.5000e-05\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.0024 - lr: 1.3500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_b,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/144 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 06:23:27.040726: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_4' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/Tanh' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_6', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_np(matrix):\n",
    "    # Calculate the number of pairs\n",
    "    n_pairs = len(matrix) // 2\n",
    "    \n",
    "    # Initialize a list to hold the sums\n",
    "    sums = []\n",
    "    \n",
    "    # Iterate through pairs of rows: first-last, second-second last, etc.\n",
    "    for i in range(n_pairs):\n",
    "        sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        \n",
    "    # If there's an odd number of rows, include the middle row\n",
    "    if len(matrix) % 2 != 0:\n",
    "        sums.append(matrix[n_pairs])\n",
    "    \n",
    "    # Flatten the resulting list of sums\n",
    "    return [num for row in sums for num in row]\n",
    "\n",
    "def pairwise_sum(matrix):\n",
    "    summed_3d_np = np.array([sum_np(layer) for layer in matrix]) / 2\n",
    "    return summed_3d_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = pairwise_sum(y_pred)\n",
    "y_test_final = pairwise_sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 96)\n",
      "(4608, 96)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0062\n",
      "rmse: 0.0786\n",
      "mae: 0.0544\n",
      "r2: 0.7441\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test_final.shape)\n",
    "print(y_pred_final.shape)\n",
    "mse = mean_squared_error(y_test_final, y_pred_final)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_final, y_pred_final)\n",
    "r2 = r2_score(y_test_final, y_pred_final)\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLOT_DIR = \"./test_plots/image_bidirectional_nn_day_ahead/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = scaler.inverse_transform(y_pred_final)\n",
    "actual_data = scaler.inverse_transform(y_test_final)\n",
    "previous_data = scaler.inverse_transform(X_test_b_flatten)\n",
    "for i in range(actual_data.shape[0]):\n",
    "    plt.figure(figsize=(24, 6))\n",
    "    X1 = np.concatenate((X_test_b_timestamp[i][-96:], y_test_timestamp[i]))\n",
    "    y1 = np.concatenate((previous_data[i][-96:], actual_data[i]))\n",
    "    X2 = y_test_timestamp[i]\n",
    "    y_p = pred_data[i]\n",
    "    y_a = actual_data[i]\n",
    "    Xh = np.full(100, X1[len(X1)-96])\n",
    "    yh = np.arange(0, 100, 1)\n",
    "    plt.title(f\"Time Series {i+1} prediction\")\n",
    "    plt.plot(X1, y1, '--', color='#98afc7')\n",
    "    plt.plot(X2, y_p, label='Predict')\n",
    "    plt.plot(X2, y_a, label='Actual')\n",
    "    plt.scatter(X2, y_p)\n",
    "    plt.scatter(X2, y_a)\n",
    "    plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./model/image_inpainting_CNN_LSTM.keras\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
