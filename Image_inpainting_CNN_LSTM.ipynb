{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse.linalg import cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 08:48:29.821063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.821163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.823790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.823896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.823969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.824035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.825304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.825389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.825458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.874305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.874398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.874470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-06 08:48:29.874533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9850 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset columns must be the format below:\\n\\n  index             Timestamp   Load\\n      0   20xx-xx-xx xx:xx:xx    xxx\\n      1                   ...    ...\\n      2                   ...    ...\\n                                 ...\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset columns must be the format below:\n",
    "\n",
    "  index             Timestamp   Load\n",
    "      0   20xx-xx-xx xx:xx:xx    xxx\n",
    "      1                   ...    ...\n",
    "      2                   ...    ...\n",
    "                                 ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>0.427049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "      <td>0.420902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>0.422951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>2023-12-31 22:45:00</td>\n",
       "      <td>0.331148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>0.270492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>2023-12-31 23:15:00</td>\n",
       "      <td>0.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>2023-12-31 23:30:00</td>\n",
       "      <td>0.337295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>2023-12-31 23:45:00</td>\n",
       "      <td>0.253689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp      Load\n",
       "0     2023-01-01 00:00:00  0.445492\n",
       "1     2023-01-01 00:15:00  0.427049\n",
       "2     2023-01-01 00:30:00  0.445492\n",
       "3     2023-01-01 00:45:00  0.420902\n",
       "4     2023-01-01 01:00:00  0.422951\n",
       "...                   ...       ...\n",
       "35035 2023-12-31 22:45:00  0.331148\n",
       "35036 2023-12-31 23:00:00  0.270492\n",
       "35037 2023-12-31 23:15:00  0.365574\n",
       "35038 2023-12-31 23:30:00  0.337295\n",
       "35039 2023-12-31 23:45:00  0.253689\n",
       "\n",
       "[35040 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 12\n",
    "height = 4\n",
    "width = 24\n",
    "n_days_b = 3\n",
    "n_days_s = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageEncoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days_b: int,\n",
    "        n_days_s: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days_b\n",
    "        self.d_s = n_days_s\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m - self.n_predict\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m - self.n_predict\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['Timestamp'].min() + DateOffset(days=self.d_b)\n",
    "        end = self.X['Timestamp'].max() - DateOffset(minutes=self.n_predict*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def generate_gaussian_noise(self, length, std_dev=0.15):\n",
    "        noise = np.random.normal(loc=0.5, scale=std_dev, size=length)\n",
    "        noise = np.clip(noise, 0, 1)\n",
    "        # noise = np.zeros(shape=length)\n",
    "        return pd.DataFrame({\"Load\": noise})\n",
    "    \n",
    "    def make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def make_it_symmetric_2d(self, sets_2d):\n",
    "        combined_slice = np.concatenate((sets_2d, sets_2d), axis=0)\n",
    "        return np.array(combined_slice).reshape(2, int(len(combined_slice)/2))\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            # noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start_b) & (self.X['Timestamp'] <= training_end)]\n",
    "            # training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            target_data = self.X[(self.X['Timestamp'] >= target_start) & (self.X['Timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data['Load'])\n",
    "                self.X_timestamp.append(training_data['Timestamp'])\n",
    "                self.y_timestamp.append(target_data['Timestamp'])\n",
    "                training_reshaped = np.array(training_data['Load']).reshape(self.d_b, self.h, self.m)\n",
    "                symmetric_3d = self.make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(symmetric_3d)\n",
    "                symmetric_2d = self.make_it_symmetric_2d(target_data['Load'])\n",
    "                target_sets.append(symmetric_2d)\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    def encode_s(self):\n",
    "        training_sets = []\n",
    "        for steps in self.timestamps:\n",
    "            training_subset = []\n",
    "            point = steps - DateOffset(days=self.d_s-1)\n",
    "            training_start = point - DateOffset(minutes=(self.m-1)*15)\n",
    "            # training\n",
    "            for _ in range(self.d_s-1):\n",
    "                training_end = training_start + DateOffset(minutes=(self.m-1)*15)\n",
    "                training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "                if not training_data.empty:\n",
    "                    symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "                    training_subset.append(symmetric_2d)\n",
    "                training_start = training_start + DateOffset(days=1)\n",
    "            training_end = training_start + DateOffset(minutes=(self.m-self.n_predict-1)*15)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "            noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "            training_subset.append(symmetric_2d)\n",
    "            training_sets.append(training_subset)\n",
    "        training_sets = np.array(training_sets)\n",
    "        return training_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 84\n",
      "Ls: 12\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageEncoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days_b=n_days_b,\n",
    "    n_days_s=n_days_s,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34740, 8, 24, 3)\n",
      "(34740, 2, 12)\n",
      "(34740, 288)\n",
      "(34740, 288)\n",
      "(34740, 12)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "# print(encoded_Xs.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30132, 8, 24, 3)\n",
      "(4608, 8, 24, 3)\n",
      "(30132, 2, 12)\n",
      "(4608, 2, 12)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 12)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('ECALayer')\n",
    "class ECALayer(Layer):\n",
    "    def __init__(self, gamma=2, b=1, **kwargs):\n",
    "        super(ECALayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.t = max(1, int(abs((tf.math.log(float(c)) / tf.math.log(2.0) + self.b) / self.gamma)))\n",
    "        self.conv = Conv1D(filters=1, kernel_size=self.t, padding='same', use_bias=False)\n",
    "        super(ECALayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Global Average Pooling over the spatial dimensions to produce a (batch_size, 1, channels) tensor\n",
    "        x = GlobalAveragePooling2D()(inputs)\n",
    "        x = Reshape((1, -1))(x)\n",
    "        x = self.conv(x)\n",
    "        x = sigmoid(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeeze to make it (batch_size, channels)\n",
    "        \n",
    "        # Multiply weights across channels\n",
    "        return inputs * x[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ECALayer, self).get_config()\n",
    "        config.update({\n",
    "            'gamma': self.gamma,\n",
    "            'b': self.b\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('AverageLayer')\n",
    "class AverageLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AverageLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs[0] + inputs[1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_shape_b, input_shape_s, num_outputs):\n",
    "#     inputs_b = Input(shape=input_shape_b)\n",
    "#     inputs_s = Input(shape=input_shape_s)\n",
    "#     conv1 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "#     conv2 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "#     conv2 = Reshape((1, *conv2.shape[1:]))(conv2)  \n",
    "#     lstm1 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv2)\n",
    "#     lstm2 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm1)\n",
    "#     eca1 = ECALayer()(lstm2)\n",
    "#     conv3 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(eca1)\n",
    "#     conv4 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "#     maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(conv4)\n",
    "#     flatten1 = Flatten()(maxpool1)\n",
    "#     dense1 = Dense(2*num_outputs, activation=\"linear\")(flatten1)\n",
    "#     outputs1 = Reshape((2, 12))(dense1)\n",
    "\n",
    "#     conv5 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(inputs_s)\n",
    "#     conv6 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv5)\n",
    "#     conv6 = Reshape((1, *conv6.shape[1:]))(conv6)  \n",
    "#     lstm3 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv6)\n",
    "#     lstm4 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm3)\n",
    "#     eca2 = ECALayer()(lstm4)\n",
    "#     conv7 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(eca2)\n",
    "#     conv8 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv7)\n",
    "#     maxpool2 = MaxPooling2D(pool_size=5, padding=\"same\")(conv8)\n",
    "#     flatten2 = Flatten()(maxpool2)\n",
    "#     dense2 = Dense(2*num_outputs, activation=\"linear\")(flatten2)\n",
    "#     outputs2 = Reshape((2, 12))(dense2)\n",
    "\n",
    "#     final_output = AverageLayer()([outputs1, outputs2])\n",
    "#     model = Model(inputs=[inputs_b, inputs_s], outputs=final_output)\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_b, num_outputs):\n",
    "    inputs_b = Input(shape=input_shape_b)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "    conv2 = Reshape((1, *conv2.shape[1:]))(conv2)\n",
    "    nor1 = BatchNormalization()(conv2)\n",
    "    lstm1 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.0))(nor1)\n",
    "    nor2 = BatchNormalization()(lstm1)\n",
    "    lstm2 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.0))(nor2)\n",
    "    nor3 = BatchNormalization()(lstm2)\n",
    "    eca1 = ECALayer()(nor3)\n",
    "    nor4 = BatchNormalization()(eca1)\n",
    "    conv3 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(nor4)\n",
    "    conv4 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "    nor5 = BatchNormalization()(conv4)\n",
    "    maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(nor5)\n",
    "    flatten1 = Flatten()(maxpool1)\n",
    "    dense1 = Dense(2*num_outputs, activation=\"linear\")(flatten1)\n",
    "    outputs = Reshape((2, 12))(dense1)\n",
    "    model = Model(inputs=inputs_b, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 24, 3)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 24, 32)         896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 24, 64)         18496     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 8, 24, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 8, 24, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1, 8, 24, 192)     1106688   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 8, 24, 192)     768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 8, 24, 192)        1991424   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " eca_layer (ECALayer)        (None, 8, 24, 192)        768       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 24, 64)         110656    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 24, 32)         18464     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 24, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 3, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                2328      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 2, 12)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3252408 (12.41 MB)\n",
      "Trainable params: 3251064 (12.40 MB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = create_model(input_shape_b=X_train_b.shape[1:], num_outputs=12)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lbfgs(model, loss_fn, x_data, y_data, learning_rate_theta=1e-5):\n",
    "    # flatten model parameters theta to 1-dim array\n",
    "    initial_params = tf.concat([tf.reshape(param, [-1]) for param in model.trainable_variables], axis=0)\n",
    "\n",
    "    # define a function to calculate loss and gradient\n",
    "    def value_and_gradients_function(params):\n",
    "        # update model parameter theta\n",
    "        assign_new_model_parameters(model, params)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_variables)\n",
    "            predictions = model(x_data, training=True)\n",
    "            loss = loss_fn(y_data, predictions)\n",
    "        # calculate the loss gradient w.r.t model parameters theta\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        flat_grads = tf.concat([tf.reshape(grad, [-1]) for grad in grads], axis=0)\n",
    "        return loss, flat_grads\n",
    "\n",
    "    # execute L-BFGS optimization\n",
    "    results = tfp.optimizer.lbfgs_minimize(\n",
    "        value_and_gradients_function,\n",
    "        initial_position=initial_params,\n",
    "        tolerance=1e-8  # adjust to appropriate training tolerance\n",
    "    )\n",
    "\n",
    "    # assign new model parameter theta\n",
    "    assign_new_model_parameters(model, results.position)\n",
    "\n",
    "def assign_new_model_parameters(model, flat_params):\n",
    "    \"\"\" Update model parameter theta \"\"\"\n",
    "    start = 0\n",
    "    for param in model.trainable_variables:\n",
    "        size = tf.size(param)\n",
    "        new_shape = tf.shape(param)\n",
    "        param.assign(tf.reshape(flat_params[start:start + size], new_shape))\n",
    "        start += size\n",
    "\n",
    "def update_weights(model, X_val, y_val, weights, learning_rate_w):\n",
    "    \"\"\" Update the weight of the sample \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(weights)\n",
    "        predictions = model(X_val, training=True)\n",
    "        loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_val[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    new_weights = tf.clip_by_value(weights - learning_rate_w * grads, 1e-5, 1)\n",
    "    return new_weights\n",
    "\n",
    "def training(model, X_train, y_train, X_val, y_val, epochs, batch_size, callbacks):\n",
    "    for callback in callbacks:\n",
    "        callback.set_model(model)\n",
    "        callback.on_train_begin()\n",
    "        \n",
    "    weights = tf.Variable(np.ones(len(X_train)) / len(X_train), dtype=tf.float32)\n",
    "    # learning rate of the sample weight\n",
    "    learning_rate_w = 5e-5\n",
    "    # learning rate of the model parameters θ\n",
    "    learning_rate_theta = 1e-5\n",
    "    # optimizer of model parameters θ\n",
    "    optimizer_theta = Adam(learning_rate=learning_rate_theta)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        for callback in callbacks:\n",
    "            callback.on_epoch_begin(epoch)\n",
    "\n",
    "        for batch in range((len(X_train) + batch_size - 1) // batch_size):\n",
    "            start = batch * batch_size\n",
    "            end = min(start + batch_size, len(X_train))\n",
    "\n",
    "            apply_lbfgs(model, lambda y_true, y_pred: tf.reduce_mean(weights[start:end] * tf.keras.losses.mean_squared_error(y_true[:, 0], tf.reduce_mean(y_pred, axis=1, keepdims=True))), X_train[start:end], y_train[start:end])\n",
    "        \n",
    "        weights.assign(update_weights(model, X_val, y_val, weights, learning_rate_w=learning_rate_w))\n",
    "\n",
    "        predictions = model(X_train, training=True)\n",
    "        val_loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_train[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "        print(f\"val_loss: {val_loss.numpy()}\")\n",
    "        \n",
    "        if early_stopping_callback.stopped_epoch:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    for callback in callbacks:\n",
    "        callback.on_train_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 08:48:55.192349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 21s 53ms/step - loss: 0.3269 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "314/314 [==============================] - 16s 52ms/step - loss: 0.0117 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "314/314 [==============================] - 16s 52ms/step - loss: 0.0088 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "314/314 [==============================] - 16s 52ms/step - loss: 0.0075 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "314/314 [==============================] - 16s 52ms/step - loss: 0.0068 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "314/314 [==============================] - 16s 52ms/step - loss: 0.0063 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0052 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0050 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0049 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0026 - lr: 5.0000e-05\n",
      "Epoch 39/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 40/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 41/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 42/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 43/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 44/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 45/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 46/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 47/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 48/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 49/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 50/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 51/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 52/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 53/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 54/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 55/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 56/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 57/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 58/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 59/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 60/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 61/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 62/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 63/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 64/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 65/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 66/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 67/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 68/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 69/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 70/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0016\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 71/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0014 - lr: 1.5000e-05\n",
      "Epoch 72/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0014 - lr: 1.5000e-05\n",
      "Epoch 73/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0014 - lr: 1.5000e-05\n",
      "Epoch 74/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0014 - lr: 1.5000e-05\n",
      "Epoch 75/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0014 - lr: 1.5000e-05\n",
      "Epoch 76/120\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.0014\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0014 - lr: 1.5000e-05\n",
      "Epoch 77/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 78/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 79/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 80/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 81/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 82/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 83/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0013\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 4.5000e-06\n",
      "Epoch 84/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 1.3500e-06\n",
      "Epoch 85/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 1.3500e-06\n",
      "Epoch 86/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 1.3500e-06\n",
      "Epoch 87/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 1.3500e-06\n",
      "Epoch 88/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0013\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 4.0499998021914507e-07.\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0013 - lr: 1.3500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_b,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/144 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 09:13:17.593465: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_6', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_6'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict([X_test_b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 12)\n",
      "(4608, 12)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0039\n",
      "rmse: 0.0627\n",
      "mae: 0.0412\n",
      "r2: 0.8386\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_final = y_pred.sum(axis=1)/2\n",
    "y_test_final = y_test.sum(axis=1)/2\n",
    "print(y_test_final.shape)\n",
    "print(y_pred_final.shape)\n",
    "mse = mean_squared_error(y_test_final, y_pred_final)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_final, y_pred_final)\n",
    "r2 = r2_score(y_test_final, y_pred_final)\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLOT_DIR = \"./test_plots/image_inpainting_bidirectional_nn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = scaler.inverse_transform(y_pred_final)\n",
    "actual_data = scaler.inverse_transform(y_test_final)\n",
    "previous_data = scaler.inverse_transform(X_test_b_flatten)\n",
    "for i in range(actual_data.shape[0]):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    X1 = np.concatenate((X_test_b_timestamp[i][-30:], y_test_timestamp[i]))\n",
    "    y1 = np.concatenate((previous_data[i][-30:], actual_data[i]))\n",
    "    X2 = y_test_timestamp[i]\n",
    "    y_p = pred_data[i]\n",
    "    y_a = actual_data[i]\n",
    "    Xh = np.full(100, X1[len(X1)-12])\n",
    "    yh = np.arange(0, 100, 1)\n",
    "    plt.title(f\"Time Series {i+1} prediction\")\n",
    "    plt.plot(X1, y1, '--', color='#98afc7')\n",
    "    plt.plot(X2, y_p, label='Predict')\n",
    "    plt.plot(X2, y_a, label='Actual')\n",
    "    plt.scatter(X2, y_p)\n",
    "    plt.scatter(X2, y_a)\n",
    "    plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/image_inpainting_CNN_LSTM_3days.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
