{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 06:13:53.875573: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:13:53.895310: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 06:13:53.895331: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 06:13:53.895350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-13 06:13:53.899575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse.linalg import cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 06:13:55.066713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.066832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.070518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.070645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.070736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.070827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.072419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.072528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.072621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.108249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.108350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.108424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-13 06:13:55.108485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9723 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset columns must be the format below:\\n\\n  index             Timestamp   Load\\n      0   20xx-xx-xx xx:xx:xx    xxx\\n      1                   ...    ...\\n      2                   ...    ...\\n                                 ...\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset columns must be the format below:\n",
    "\n",
    "  index             Timestamp   Load\n",
    "      0   20xx-xx-xx xx:xx:xx    xxx\n",
    "      1                   ...    ...\n",
    "      2                   ...    ...\n",
    "                                 ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>0.427049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "      <td>0.420902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>0.422951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>2023-12-31 22:45:00</td>\n",
       "      <td>0.331148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>0.270492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>2023-12-31 23:15:00</td>\n",
       "      <td>0.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>2023-12-31 23:30:00</td>\n",
       "      <td>0.337295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>2023-12-31 23:45:00</td>\n",
       "      <td>0.253689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp      Load\n",
       "0     2023-01-01 00:00:00  0.445492\n",
       "1     2023-01-01 00:15:00  0.427049\n",
       "2     2023-01-01 00:30:00  0.445492\n",
       "3     2023-01-01 00:45:00  0.420902\n",
       "4     2023-01-01 01:00:00  0.422951\n",
       "...                   ...       ...\n",
       "35035 2023-12-31 22:45:00  0.331148\n",
       "35036 2023-12-31 23:00:00  0.270492\n",
       "35037 2023-12-31 23:15:00  0.365574\n",
       "35038 2023-12-31 23:30:00  0.337295\n",
       "35039 2023-12-31 23:45:00  0.253689\n",
       "\n",
       "[35040 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 96\n",
    "height = 4\n",
    "width = 24\n",
    "n_days_b = 3\n",
    "n_days_s = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageEncoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days_b: int,\n",
    "        n_days_s: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days_b\n",
    "        self.d_s = n_days_s\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['Timestamp'].min() + DateOffset(days=self.d_b)\n",
    "        end = self.X['Timestamp'].max() - DateOffset(minutes=self.n_predict*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def generate_gaussian_noise(self, length, std_dev=0.15):\n",
    "        noise = np.random.normal(loc=0.5, scale=std_dev, size=length)\n",
    "        noise = np.clip(noise, 0, 1)\n",
    "        # noise = np.zeros(shape=length)\n",
    "        return pd.DataFrame({\"Load\": noise})\n",
    "    \n",
    "    def make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            # noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start_b) & (self.X['Timestamp'] <= training_end)]\n",
    "            # training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            target_data = self.X[(self.X['Timestamp'] >= target_start) & (self.X['Timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data['Load'])\n",
    "                self.X_timestamp.append(training_data['Timestamp'])\n",
    "                self.y_timestamp.append(target_data['Timestamp'])\n",
    "                training_reshaped = np.array(training_data['Load']).reshape(self.d_b, self.h, self.m)\n",
    "                symmetric_3d = self.make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(symmetric_3d)\n",
    "                target_reshaped = np.array(target_data['Load']).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                symmetric_2d = self.make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(symmetric_2d)\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    # def encode_s(self):\n",
    "    #     training_sets = []\n",
    "    #     for steps in self.timestamps:\n",
    "    #         training_subset = []\n",
    "    #         point = steps - DateOffset(days=self.d_s-1)\n",
    "    #         training_start = point - DateOffset(minutes=(self.m-1)*15)\n",
    "    #         # training\n",
    "    #         for _ in range(self.d_s-1):\n",
    "    #             training_end = training_start + DateOffset(minutes=(self.m-1)*15)\n",
    "    #             training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "    #             if not training_data.empty:\n",
    "    #                 symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "    #                 training_subset.append(symmetric_2d)\n",
    "    #             training_start = training_start + DateOffset(days=1)\n",
    "    #         training_end = training_start + DateOffset(minutes=(self.m-self.n_predict-1)*15)\n",
    "    #         training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "    #         noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "    #         training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "    #         symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "    #         training_subset.append(symmetric_2d)\n",
    "    #         training_sets.append(training_subset)\n",
    "    #     training_sets = np.array(training_sets)\n",
    "    #     return training_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 96\n",
      "Ls: 96\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageEncoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days_b=n_days_b,\n",
    "    n_days_s=n_days_s,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34656, 8, 24, 3)\n",
      "(34656, 8, 24)\n",
      "(34656, 288)\n",
      "(34656, 288)\n",
      "(34656, 96)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 8, 24, 3)\n",
      "(4608, 8, 24, 3)\n",
      "(30048, 8, 24)\n",
      "(4608, 8, 24)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 96)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('ECALayer')\n",
    "class ECALayer(Layer):\n",
    "    def __init__(self, gamma=2, b=1, **kwargs):\n",
    "        super(ECALayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.t = max(1, int(abs((tf.math.log(float(c)) / tf.math.log(2.0) + self.b) / self.gamma)))\n",
    "        self.conv = Conv1D(filters=1, kernel_size=self.t, padding='same', use_bias=False)\n",
    "        super(ECALayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Global Average Pooling over the spatial dimensions to produce a (batch_size, 1, channels) tensor\n",
    "        x = GlobalAveragePooling2D()(inputs)\n",
    "        x = Reshape((1, -1))(x)\n",
    "        x = self.conv(x)\n",
    "        x = sigmoid(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeeze to make it (batch_size, channels)\n",
    "        \n",
    "        # Multiply weights across channels\n",
    "        return inputs * x[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ECALayer, self).get_config()\n",
    "        config.update({\n",
    "            'gamma': self.gamma,\n",
    "            'b': self.b\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('AverageLayer')\n",
    "class AverageLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AverageLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs[0] + inputs[1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_shape_b, input_shape_s, num_outputs):\n",
    "#     inputs_b = Input(shape=input_shape_b)\n",
    "#     inputs_s = Input(shape=input_shape_s)\n",
    "#     conv1 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "#     conv2 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "#     conv2 = Reshape((1, *conv2.shape[1:]))(conv2)  \n",
    "#     lstm1 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv2)\n",
    "#     lstm2 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm1)\n",
    "#     eca1 = ECALayer()(lstm2)\n",
    "#     conv3 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(eca1)\n",
    "#     conv4 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "#     maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(conv4)\n",
    "#     flatten1 = Flatten()(maxpool1)\n",
    "#     dense1 = Dense(2*num_outputs, activation=\"linear\")(flatten1)\n",
    "#     outputs1 = Reshape((2, 12))(dense1)\n",
    "\n",
    "#     conv5 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(inputs_s)\n",
    "#     conv6 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv5)\n",
    "#     conv6 = Reshape((1, *conv6.shape[1:]))(conv6)  \n",
    "#     lstm3 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv6)\n",
    "#     lstm4 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm3)\n",
    "#     eca2 = ECALayer()(lstm4)\n",
    "#     conv7 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(eca2)\n",
    "#     conv8 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv7)\n",
    "#     maxpool2 = MaxPooling2D(pool_size=5, padding=\"same\")(conv8)\n",
    "#     flatten2 = Flatten()(maxpool2)\n",
    "#     dense2 = Dense(2*num_outputs, activation=\"linear\")(flatten2)\n",
    "#     outputs2 = Reshape((2, 12))(dense2)\n",
    "\n",
    "#     final_output = AverageLayer()([outputs1, outputs2])\n",
    "#     model = Model(inputs=[inputs_b, inputs_s], outputs=final_output)\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_b, encoder):\n",
    "    height, width = math.ceil(encoder.n_predict / encoder.m) * 2, min(encoder.n_predict, encoder.m)\n",
    "    inputs_b = Input(shape=input_shape_b)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "    conv2 = Reshape((1, *conv2.shape[1:]))(conv2)\n",
    "    nor1 = BatchNormalization()(conv2)\n",
    "    lstm1 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.0))(nor1)\n",
    "    nor2 = BatchNormalization()(lstm1)\n",
    "    lstm2 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.0))(nor2)\n",
    "    nor3 = BatchNormalization()(lstm2)\n",
    "    eca1 = ECALayer()(nor3)\n",
    "    nor4 = BatchNormalization()(eca1)\n",
    "    conv3 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(nor4)\n",
    "    conv4 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "    nor5 = BatchNormalization()(conv4)\n",
    "    maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(nor5)\n",
    "    flatten1 = Flatten()(maxpool1)\n",
    "    dense1 = Dense(height*width, activation=\"linear\")(flatten1)\n",
    "    outputs = Reshape((height, width))(dense1)\n",
    "    model = Model(inputs=inputs_b, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 24, 3)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 24, 32)         896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 24, 64)         18496     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 8, 24, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 8, 24, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1, 8, 24, 192)     1106688   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 8, 24, 192)     768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 8, 24, 192)        1991424   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " eca_layer (ECALayer)        (None, 8, 24, 192)        768       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 24, 64)         110656    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 24, 32)         18464     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 24, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 3, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               18624     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 8, 24)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3268704 (12.47 MB)\n",
      "Trainable params: 3267360 (12.46 MB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = create_model(input_shape_b=X_train_b.shape[1:], encoder=encoder)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lbfgs(model, loss_fn, x_data, y_data, learning_rate_theta=1e-5):\n",
    "    # flatten model parameters theta to 1-dim array\n",
    "    initial_params = tf.concat([tf.reshape(param, [-1]) for param in model.trainable_variables], axis=0)\n",
    "\n",
    "    # define a function to calculate loss and gradient\n",
    "    def value_and_gradients_function(params):\n",
    "        # update model parameter theta\n",
    "        assign_new_model_parameters(model, params)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_variables)\n",
    "            predictions = model(x_data, training=True)\n",
    "            loss = loss_fn(y_data, predictions)\n",
    "        # calculate the loss gradient w.r.t model parameters theta\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        flat_grads = tf.concat([tf.reshape(grad, [-1]) for grad in grads], axis=0)\n",
    "        return loss, flat_grads\n",
    "\n",
    "    # execute L-BFGS optimization\n",
    "    results = tfp.optimizer.lbfgs_minimize(\n",
    "        value_and_gradients_function,\n",
    "        initial_position=initial_params,\n",
    "        tolerance=1e-8  # adjust to appropriate training tolerance\n",
    "    )\n",
    "\n",
    "    # assign new model parameter theta\n",
    "    assign_new_model_parameters(model, results.position)\n",
    "\n",
    "def assign_new_model_parameters(model, flat_params):\n",
    "    \"\"\" Update model parameter theta \"\"\"\n",
    "    start = 0\n",
    "    for param in model.trainable_variables:\n",
    "        size = tf.size(param)\n",
    "        new_shape = tf.shape(param)\n",
    "        param.assign(tf.reshape(flat_params[start:start + size], new_shape))\n",
    "        start += size\n",
    "\n",
    "def update_weights(model, X_val, y_val, weights, learning_rate_w):\n",
    "    \"\"\" Update the weight of the sample \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(weights)\n",
    "        predictions = model(X_val, training=True)\n",
    "        loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_val[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    new_weights = tf.clip_by_value(weights - learning_rate_w * grads, 1e-5, 1)\n",
    "    return new_weights\n",
    "\n",
    "def training(model, X_train, y_train, X_val, y_val, epochs, batch_size, callbacks):\n",
    "    for callback in callbacks:\n",
    "        callback.set_model(model)\n",
    "        callback.on_train_begin()\n",
    "        \n",
    "    weights = tf.Variable(np.ones(len(X_train)) / len(X_train), dtype=tf.float32)\n",
    "    # learning rate of the sample weight\n",
    "    learning_rate_w = 5e-5\n",
    "    # learning rate of the model parameters θ\n",
    "    learning_rate_theta = 1e-5\n",
    "    # optimizer of model parameters θ\n",
    "    optimizer_theta = Adam(learning_rate=learning_rate_theta)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        for callback in callbacks:\n",
    "            callback.on_epoch_begin(epoch)\n",
    "\n",
    "        for batch in range((len(X_train) + batch_size - 1) // batch_size):\n",
    "            start = batch * batch_size\n",
    "            end = min(start + batch_size, len(X_train))\n",
    "\n",
    "            apply_lbfgs(model, lambda y_true, y_pred: tf.reduce_mean(weights[start:end] * tf.keras.losses.mean_squared_error(y_true[:, 0], tf.reduce_mean(y_pred, axis=1, keepdims=True))), X_train[start:end], y_train[start:end])\n",
    "        \n",
    "        weights.assign(update_weights(model, X_val, y_val, weights, learning_rate_w=learning_rate_w))\n",
    "\n",
    "        predictions = model(X_train, training=True)\n",
    "        val_loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_train[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "        print(f\"val_loss: {val_loss.numpy()}\")\n",
    "        \n",
    "        if early_stopping_callback.stopped_epoch:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    for callback in callbacks:\n",
    "        callback.on_train_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 06:14:20.006614: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/model/bidirectional_1/forward_conv_lstm2d_1/while_grad/body/_753/input/_2066' -> 'gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/model/bidirectional_1/forward_conv_lstm2d_1/while_grad/body/_753/gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/model/bidirectional_1/backward_conv_lstm2d_1/while_grad/body/_948/input/_2185' -> 'gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/model/bidirectional_1/backward_conv_lstm2d_1/while_grad/body/_948/gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional/backward_conv_lstm2d/while/model/bidirectional/backward_conv_lstm2d/while_grad/body/_1338/input/_2423' -> 'gradient_tape/model/bidirectional/backward_conv_lstm2d/while/model/bidirectional/backward_conv_lstm2d/while_grad/body/_1338/gradient_tape/model/bidirectional/backward_conv_lstm2d/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional/forward_conv_lstm2d/while/model/bidirectional/forward_conv_lstm2d/while_grad/body/_1143/input/_2304' -> 'gradient_tape/model/bidirectional/forward_conv_lstm2d/while/model/bidirectional/forward_conv_lstm2d/while_grad/body/_1143/gradient_tape/model/bidirectional/forward_conv_lstm2d/while/gradients/AddN', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_6' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/add_4', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/clip_by_value' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_6' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/add_4'}.\n",
      "2024-05-13 06:14:20.444483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 23s 63ms/step - loss: 0.2751 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0337 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0188 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0171 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0161 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0150 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0138 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0127 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0117 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0108 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0101 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0095 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0090 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0086 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0082 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0079 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0076 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0074 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0071 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0069 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0067 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0066 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0064 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.0062 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0052 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0050 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0049 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0048 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0046 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 1.5000e-05\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0025 - lr: 4.5000e-06\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 4.5000e-06\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 1.3500e-06\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 1.3500e-06\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 1.3500e-06\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 1.3500e-06\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 1.3500e-06\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 4.0499998021914507e-07.\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0024 - lr: 1.3500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_b,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/144 [..............................] - ETA: 1:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 06:46:19.439227: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_4' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/Tanh' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_6', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_np(matrix):\n",
    "    # Calculate the number of pairs\n",
    "    n_pairs = len(matrix) // 2\n",
    "    \n",
    "    # Initialize a list to hold the sums\n",
    "    sums = []\n",
    "    \n",
    "    # Iterate through pairs of rows: first-last, second-second last, etc.\n",
    "    for i in range(n_pairs):\n",
    "        sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        \n",
    "    # If there's an odd number of rows, include the middle row\n",
    "    if len(matrix) % 2 != 0:\n",
    "        sums.append(matrix[n_pairs])\n",
    "    \n",
    "    # Flatten the resulting list of sums\n",
    "    return [num for row in sums for num in row]\n",
    "\n",
    "def pairwise_sum(matrix):\n",
    "    summed_3d_np = np.array([sum_np(layer) for layer in matrix]) / 2\n",
    "    return summed_3d_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = pairwise_sum(y_pred)\n",
    "y_test_final = pairwise_sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 96)\n",
      "(4608, 96)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0060\n",
      "rmse: 0.0772\n",
      "mae: 0.0540\n",
      "r2: 0.7530\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test_final.shape)\n",
    "print(y_pred_final.shape)\n",
    "mse = mean_squared_error(y_test_final, y_pred_final)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_final, y_pred_final)\n",
    "r2 = r2_score(y_test_final, y_pred_final)\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLOT_DIR = \"./test_plots/bi_nn_96steps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = scaler.inverse_transform(y_pred_final)\n",
    "actual_data = scaler.inverse_transform(y_test_final)\n",
    "previous_data = scaler.inverse_transform(X_test_b_flatten)\n",
    "\n",
    "for i in range(actual_data.shape[0]):\n",
    "    history = None\n",
    "    history_timestamp = None\n",
    "    index = i % 192\n",
    "    if index < 47:\n",
    "        history = pred_data[i-index:i+1, 0]\n",
    "        history_timestamp = y_test_timestamp[i-index:i+1, 0]\n",
    "    else:\n",
    "        history = pred_data[i-48:i+1, 0]\n",
    "        history_timestamp = y_test_timestamp[i-48:i+1, 0]\n",
    "        \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    X1 = np.concatenate((X_test_b_timestamp[i][-48:], y_test_timestamp[i]))\n",
    "    y1 = np.concatenate((previous_data[i][-48:], actual_data[i]))\n",
    "    X2 = y_test_timestamp[i]\n",
    "    y_p = pred_data[i]\n",
    "    y_a = actual_data[i]\n",
    "    Xh = np.full(100, X1[len(X1)-96])\n",
    "    yh = np.arange(0, 100, 1)\n",
    "    plt.title(f\"Time Series {i+1} prediction\")\n",
    "    plt.plot(X1, y1, '.-', label='Actual', color='#6eb5c0')\n",
    "    plt.plot(X2, y_p, '.-', label='Predict', color='#174d7c')\n",
    "    plt.plot(history_timestamp, history, '--', label='History', color='#989898')\n",
    "    plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/image_inpainting_CNN_LSTM_96steps.keras\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
