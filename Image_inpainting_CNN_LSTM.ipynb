{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 09:51:37.597105: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-08 09:51:37.616405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-08 09:51:37.616426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-08 09:51:37.616440: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-08 09:51:37.620576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse.linalg import cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 09:51:38.710579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.710677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.713304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.713427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.713495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.713557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.714572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.714655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.714715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.761531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.761622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.761686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-08 09:51:38.761743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset columns must be the format below:\\n\\n  index             Timestamp   Load\\n      0   20xx-xx-xx xx:xx:xx    xxx\\n      1                   ...    ...\\n      2                   ...    ...\\n                                 ...\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset columns must be the format below:\n",
    "\n",
    "  index             Timestamp   Load\n",
    "      0   20xx-xx-xx xx:xx:xx    xxx\n",
    "      1                   ...    ...\n",
    "      2                   ...    ...\n",
    "                                 ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>0.427049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "      <td>0.420902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>0.422951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>2023-12-31 22:45:00</td>\n",
       "      <td>0.331148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>0.270492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>2023-12-31 23:15:00</td>\n",
       "      <td>0.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>2023-12-31 23:30:00</td>\n",
       "      <td>0.337295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>2023-12-31 23:45:00</td>\n",
       "      <td>0.253689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp      Load\n",
       "0     2023-01-01 00:00:00  0.445492\n",
       "1     2023-01-01 00:15:00  0.427049\n",
       "2     2023-01-01 00:30:00  0.445492\n",
       "3     2023-01-01 00:45:00  0.420902\n",
       "4     2023-01-01 01:00:00  0.422951\n",
       "...                   ...       ...\n",
       "35035 2023-12-31 22:45:00  0.331148\n",
       "35036 2023-12-31 23:00:00  0.270492\n",
       "35037 2023-12-31 23:15:00  0.365574\n",
       "35038 2023-12-31 23:30:00  0.337295\n",
       "35039 2023-12-31 23:45:00  0.253689\n",
       "\n",
       "[35040 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 12\n",
    "height = 4\n",
    "width = 24\n",
    "n_days_b = 3\n",
    "n_days_s = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageEncoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days_b: int,\n",
    "        n_days_s: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days_b\n",
    "        self.d_s = n_days_s\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['Timestamp'].min() + DateOffset(days=self.d_b)\n",
    "        end = self.X['Timestamp'].max() - DateOffset(minutes=self.n_predict*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def generate_gaussian_noise(self, length, std_dev=0.15):\n",
    "        noise = np.random.normal(loc=0.5, scale=std_dev, size=length)\n",
    "        noise = np.clip(noise, 0, 1)\n",
    "        # noise = np.zeros(shape=length)\n",
    "        return pd.DataFrame({\"Load\": noise})\n",
    "    \n",
    "    def make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            # noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start_b) & (self.X['Timestamp'] <= training_end)]\n",
    "            # training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            target_data = self.X[(self.X['Timestamp'] >= target_start) & (self.X['Timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data['Load'])\n",
    "                self.X_timestamp.append(training_data['Timestamp'])\n",
    "                self.y_timestamp.append(target_data['Timestamp'])\n",
    "                training_reshaped = np.array(training_data['Load']).reshape(self.d_b, self.h, self.m)\n",
    "                symmetric_3d = self.make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(symmetric_3d)\n",
    "                target_reshaped = np.array(target_data['Load']).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                symmetric_2d = self.make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(symmetric_2d)\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    # def encode_s(self):\n",
    "    #     training_sets = []\n",
    "    #     for steps in self.timestamps:\n",
    "    #         training_subset = []\n",
    "    #         point = steps - DateOffset(days=self.d_s-1)\n",
    "    #         training_start = point - DateOffset(minutes=(self.m-1)*15)\n",
    "    #         # training\n",
    "    #         for _ in range(self.d_s-1):\n",
    "    #             training_end = training_start + DateOffset(minutes=(self.m-1)*15)\n",
    "    #             training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "    #             if not training_data.empty:\n",
    "    #                 symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "    #                 training_subset.append(symmetric_2d)\n",
    "    #             training_start = training_start + DateOffset(days=1)\n",
    "    #         training_end = training_start + DateOffset(minutes=(self.m-self.n_predict-1)*15)\n",
    "    #         training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "    #         noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "    #         training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "    #         symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "    #         training_subset.append(symmetric_2d)\n",
    "    #         training_sets.append(training_subset)\n",
    "    #     training_sets = np.array(training_sets)\n",
    "    #     return training_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 96\n",
      "Ls: 24\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageEncoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days_b=n_days_b,\n",
    "    n_days_s=n_days_s,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34740, 8, 24, 3)\n",
      "(34740, 2, 12)\n",
      "(34740, 288)\n",
      "(34740, 288)\n",
      "(34740, 12)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30132, 8, 24, 3)\n",
      "(4608, 8, 24, 3)\n",
      "(30132, 2, 12)\n",
      "(4608, 2, 12)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 12)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('ECALayer')\n",
    "class ECALayer(Layer):\n",
    "    def __init__(self, gamma=2, b=1, **kwargs):\n",
    "        super(ECALayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.t = max(1, int(abs((tf.math.log(float(c)) / tf.math.log(2.0) + self.b) / self.gamma)))\n",
    "        self.conv = Conv1D(filters=1, kernel_size=self.t, padding='same', use_bias=False)\n",
    "        super(ECALayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Global Average Pooling over the spatial dimensions to produce a (batch_size, 1, channels) tensor\n",
    "        x = GlobalAveragePooling2D()(inputs)\n",
    "        x = Reshape((1, -1))(x)\n",
    "        x = self.conv(x)\n",
    "        x = sigmoid(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeeze to make it (batch_size, channels)\n",
    "        \n",
    "        # Multiply weights across channels\n",
    "        return inputs * x[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ECALayer, self).get_config()\n",
    "        config.update({\n",
    "            'gamma': self.gamma,\n",
    "            'b': self.b\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('AverageLayer')\n",
    "class AverageLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AverageLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs[0] + inputs[1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_shape_b, input_shape_s, num_outputs):\n",
    "#     inputs_b = Input(shape=input_shape_b)\n",
    "#     inputs_s = Input(shape=input_shape_s)\n",
    "#     conv1 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "#     conv2 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "#     conv2 = Reshape((1, *conv2.shape[1:]))(conv2)  \n",
    "#     lstm1 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv2)\n",
    "#     lstm2 = ConvLSTM2D(filters=96, kernel_size=8, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm1)\n",
    "#     eca1 = ECALayer()(lstm2)\n",
    "#     conv3 = Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"tanh\")(eca1)\n",
    "#     conv4 = Conv2D(filters=32, kernel_size=8, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "#     maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(conv4)\n",
    "#     flatten1 = Flatten()(maxpool1)\n",
    "#     dense1 = Dense(2*num_outputs, activation=\"linear\")(flatten1)\n",
    "#     outputs1 = Reshape((2, 12))(dense1)\n",
    "\n",
    "#     conv5 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(inputs_s)\n",
    "#     conv6 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv5)\n",
    "#     conv6 = Reshape((1, *conv6.shape[1:]))(conv6)  \n",
    "#     lstm3 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.3)(conv6)\n",
    "#     lstm4 = ConvLSTM2D(filters=24, kernel_size=2, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.3)(lstm3)\n",
    "#     eca2 = ECALayer()(lstm4)\n",
    "#     conv7 = Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"tanh\")(eca2)\n",
    "#     conv8 = Conv2D(filters=8, kernel_size=2, padding=\"same\", activation=\"tanh\")(conv7)\n",
    "#     maxpool2 = MaxPooling2D(pool_size=5, padding=\"same\")(conv8)\n",
    "#     flatten2 = Flatten()(maxpool2)\n",
    "#     dense2 = Dense(2*num_outputs, activation=\"linear\")(flatten2)\n",
    "#     outputs2 = Reshape((2, 12))(dense2)\n",
    "\n",
    "#     final_output = AverageLayer()([outputs1, outputs2])\n",
    "#     model = Model(inputs=[inputs_b, inputs_s], outputs=final_output)\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_b, encoder):\n",
    "    height, width = math.ceil(encoder.n_predict / encoder.m) * 2, min(encoder.n_predict, encoder.m)\n",
    "    inputs_b = Input(shape=input_shape_b)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "    conv2 = Reshape((1, *conv2.shape[1:]))(conv2)\n",
    "    nor1 = BatchNormalization()(conv2)\n",
    "    lstm1 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.0))(nor1)\n",
    "    nor2 = BatchNormalization()(lstm1)\n",
    "    lstm2 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.0))(nor2)\n",
    "    nor3 = BatchNormalization()(lstm2)\n",
    "    eca1 = ECALayer()(nor3)\n",
    "    nor4 = BatchNormalization()(eca1)\n",
    "    conv3 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(nor4)\n",
    "    conv4 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "    nor5 = BatchNormalization()(conv4)\n",
    "    maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(nor5)\n",
    "    flatten1 = Flatten()(maxpool1)\n",
    "    dense1 = Dense(height*width, activation=\"linear\")(flatten1)\n",
    "    outputs = Reshape((height, width))(dense1)\n",
    "    model = Model(inputs=inputs_b, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 24, 3)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 24, 32)         896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 24, 64)         18496     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 8, 24, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 8, 24, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1, 8, 24, 192)     1106688   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 8, 24, 192)     768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 8, 24, 192)        1991424   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " eca_layer (ECALayer)        (None, 8, 24, 192)        768       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 24, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 24, 64)         110656    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 24, 32)         18464     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 24, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 3, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                2328      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 2, 12)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3252408 (12.41 MB)\n",
      "Trainable params: 3251064 (12.40 MB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = create_model(input_shape_b=X_train_b.shape[1:], encoder=encoder)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lbfgs(model, loss_fn, x_data, y_data, learning_rate_theta=1e-5):\n",
    "    # flatten model parameters theta to 1-dim array\n",
    "    initial_params = tf.concat([tf.reshape(param, [-1]) for param in model.trainable_variables], axis=0)\n",
    "\n",
    "    # define a function to calculate loss and gradient\n",
    "    def value_and_gradients_function(params):\n",
    "        # update model parameter theta\n",
    "        assign_new_model_parameters(model, params)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_variables)\n",
    "            predictions = model(x_data, training=True)\n",
    "            loss = loss_fn(y_data, predictions)\n",
    "        # calculate the loss gradient w.r.t model parameters theta\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        flat_grads = tf.concat([tf.reshape(grad, [-1]) for grad in grads], axis=0)\n",
    "        return loss, flat_grads\n",
    "\n",
    "    # execute L-BFGS optimization\n",
    "    results = tfp.optimizer.lbfgs_minimize(\n",
    "        value_and_gradients_function,\n",
    "        initial_position=initial_params,\n",
    "        tolerance=1e-8  # adjust to appropriate training tolerance\n",
    "    )\n",
    "\n",
    "    # assign new model parameter theta\n",
    "    assign_new_model_parameters(model, results.position)\n",
    "\n",
    "def assign_new_model_parameters(model, flat_params):\n",
    "    \"\"\" Update model parameter theta \"\"\"\n",
    "    start = 0\n",
    "    for param in model.trainable_variables:\n",
    "        size = tf.size(param)\n",
    "        new_shape = tf.shape(param)\n",
    "        param.assign(tf.reshape(flat_params[start:start + size], new_shape))\n",
    "        start += size\n",
    "\n",
    "def update_weights(model, X_val, y_val, weights, learning_rate_w):\n",
    "    \"\"\" Update the weight of the sample \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(weights)\n",
    "        predictions = model(X_val, training=True)\n",
    "        loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_val[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    new_weights = tf.clip_by_value(weights - learning_rate_w * grads, 1e-5, 1)\n",
    "    return new_weights\n",
    "\n",
    "def training(model, X_train, y_train, X_val, y_val, epochs, batch_size, callbacks):\n",
    "    for callback in callbacks:\n",
    "        callback.set_model(model)\n",
    "        callback.on_train_begin()\n",
    "        \n",
    "    weights = tf.Variable(np.ones(len(X_train)) / len(X_train), dtype=tf.float32)\n",
    "    # learning rate of the sample weight\n",
    "    learning_rate_w = 5e-5\n",
    "    # learning rate of the model parameters θ\n",
    "    learning_rate_theta = 1e-5\n",
    "    # optimizer of model parameters θ\n",
    "    optimizer_theta = Adam(learning_rate=learning_rate_theta)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        for callback in callbacks:\n",
    "            callback.on_epoch_begin(epoch)\n",
    "\n",
    "        for batch in range((len(X_train) + batch_size - 1) // batch_size):\n",
    "            start = batch * batch_size\n",
    "            end = min(start + batch_size, len(X_train))\n",
    "\n",
    "            apply_lbfgs(model, lambda y_true, y_pred: tf.reduce_mean(weights[start:end] * tf.keras.losses.mean_squared_error(y_true[:, 0], tf.reduce_mean(y_pred, axis=1, keepdims=True))), X_train[start:end], y_train[start:end])\n",
    "        \n",
    "        weights.assign(update_weights(model, X_val, y_val, weights, learning_rate_w=learning_rate_w))\n",
    "\n",
    "        predictions = model(X_train, training=True)\n",
    "        val_loss = tf.reduce_mean(weights * tf.keras.losses.mean_squared_error(y_train[:, 0], tf.reduce_mean(predictions, axis=1, keepdims=True)))\n",
    "        print(f\"val_loss: {val_loss.numpy()}\")\n",
    "        \n",
    "        if early_stopping_callback.stopped_epoch:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    for callback in callbacks:\n",
    "        callback.on_train_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 09:52:04.852396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 21s 54ms/step - loss: 0.4068 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "314/314 [==============================] - 16s 52ms/step - loss: 0.0193 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "314/314 [==============================] - 17s 53ms/step - loss: 0.0133 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0109 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0095 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0085 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "314/314 [==============================] - 18s 56ms/step - loss: 0.0079 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "314/314 [==============================] - 18s 56ms/step - loss: 0.0073 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "314/314 [==============================] - 17s 56ms/step - loss: 0.0068 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "314/314 [==============================] - 18s 56ms/step - loss: 0.0064 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "314/314 [==============================] - 17s 56ms/step - loss: 0.0061 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "314/314 [==============================] - 17s 56ms/step - loss: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "314/314 [==============================] - 17s 56ms/step - loss: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "314/314 [==============================] - 17s 56ms/step - loss: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0052 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0050 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0049 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0048 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0047 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "314/314 [==============================] - 17s 55ms/step - loss: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0031 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 39/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0029 - lr: 5.0000e-05\n",
      "Epoch 40/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 41/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 42/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 43/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 44/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0026 - lr: 5.0000e-05\n",
      "Epoch 45/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 46/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 47/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 48/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 49/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 50/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 51/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 52/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 53/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 54/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 55/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 56/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 57/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 58/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 59/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 60/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 61/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 62/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 63/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 64/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0019\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 65/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 66/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 67/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0017 - lr: 1.5000e-05\n",
      "Epoch 68/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0016 - lr: 1.5000e-05\n",
      "Epoch 69/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0016 - lr: 1.5000e-05\n",
      "Epoch 70/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0016\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0016 - lr: 1.5000e-05\n",
      "Epoch 71/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 72/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 73/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0016 - lr: 4.5000e-06\n",
      "Epoch 74/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.5000e-06\n",
      "Epoch 75/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.5000e-06\n",
      "Epoch 76/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0015\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.5000e-06\n",
      "Epoch 77/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 78/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 79/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 80/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 81/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0015\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.0499998021914507e-07.\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.3500e-06\n",
      "Epoch 82/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 83/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 84/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 85/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 86/120\n",
      "313/314 [============================>.] - ETA: 0s - loss: 0.0015\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.2149999406574352e-07.\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 4.0500e-07\n",
      "Epoch 87/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.2150e-07\n",
      "Epoch 88/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.2150e-07\n",
      "Epoch 89/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.2150e-07\n",
      "Epoch 90/120\n",
      "314/314 [==============================] - 17s 54ms/step - loss: 0.0015 - lr: 1.2150e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_b,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/144 [..............................] - ETA: 1:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 10:17:38.352126: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_6', 'Func/model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/input/_326' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_6'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_np(matrix):\n",
    "    # Calculate the number of pairs\n",
    "    n_pairs = len(matrix) // 2\n",
    "    \n",
    "    # Initialize a list to hold the sums\n",
    "    sums = []\n",
    "    \n",
    "    # Iterate through pairs of rows: first-last, second-second last, etc.\n",
    "    for i in range(n_pairs):\n",
    "        sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        \n",
    "    # If there's an odd number of rows, include the middle row\n",
    "    if len(matrix) % 2 != 0:\n",
    "        sums.append(matrix[n_pairs])\n",
    "    \n",
    "    # Flatten the resulting list of sums\n",
    "    return [num for row in sums for num in row]\n",
    "\n",
    "def pairwise_sum(matrix):\n",
    "    summed_3d_np = np.array([sum_np(layer) for layer in matrix]) / 2\n",
    "    return summed_3d_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = pairwise_sum(y_pred)\n",
    "y_test_final = pairwise_sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 12)\n",
      "(4608, 12)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0040\n",
      "rmse: 0.0632\n",
      "mae: 0.0427\n",
      "r2: 0.8362\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test_final.shape)\n",
    "print(y_pred_final.shape)\n",
    "mse = mean_squared_error(y_test_final, y_pred_final)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_final, y_pred_final)\n",
    "r2 = r2_score(y_test_final, y_pred_final)\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLOT_DIR = \"./test_plots/image_inpainting_bidirectional_nn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "if not os.path.exists(\"./training_history\"):\n",
    "    os.makedirs(\"./training_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = scaler.inverse_transform(y_pred_final)\n",
    "actual_data = scaler.inverse_transform(y_test_final)\n",
    "previous_data = scaler.inverse_transform(X_test_b_flatten)\n",
    "for i in range(actual_data.shape[0]):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    X1 = np.concatenate((X_test_b_timestamp[i][-30:], y_test_timestamp[i]))\n",
    "    y1 = np.concatenate((previous_data[i][-30:], actual_data[i]))\n",
    "    X2 = y_test_timestamp[i]\n",
    "    y_p = pred_data[i]\n",
    "    y_a = actual_data[i]\n",
    "    Xh = np.full(100, X1[len(X1)-12])\n",
    "    yh = np.arange(0, 100, 1)\n",
    "    plt.title(f\"Time Series {i+1} prediction\")\n",
    "    plt.plot(X1, y1, '--', color='#98afc7')\n",
    "    plt.plot(X2, y_p, label='Predict')\n",
    "    plt.plot(X2, y_a, label='Actual')\n",
    "    plt.scatter(X2, y_p)\n",
    "    plt.scatter(X2, y_a)\n",
    "    plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/image_inpainting_CNN_LSTM.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
