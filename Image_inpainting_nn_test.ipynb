{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 10:38:00.390857: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-12 10:38:00.410213: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-12 10:38:00.410232: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-12 10:38:00.410248: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-12 10:38:00.414683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Conv1D, GlobalAveragePooling2D, Reshape, Layer\n",
    "from keras.activations import sigmoid\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 10:38:01.375399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.375497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.377980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.378079: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.378150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.378212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.379287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.379370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.379431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.416220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.416315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.416385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 10:38:01.416447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9919 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset columns must be the format below:\\n\\n  index             Timestamp   Load\\n      0   20xx-xx-xx xx:xx:xx    xxx\\n      1                   ...    ...\\n      2                   ...    ...\\n                                 ...\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The dataset columns must be the format below:\n",
    "\n",
    "  index             Timestamp   Load\n",
    "      0   20xx-xx-xx xx:xx:xx    xxx\n",
    "      1                   ...    ...\n",
    "      2                   ...    ...\n",
    "                                 ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>0.427049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>0.445492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "      <td>0.420902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>0.422951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>2023-12-31 22:45:00</td>\n",
       "      <td>0.331148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>0.270492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>2023-12-31 23:15:00</td>\n",
       "      <td>0.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>2023-12-31 23:30:00</td>\n",
       "      <td>0.337295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>2023-12-31 23:45:00</td>\n",
       "      <td>0.253689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp      Load\n",
       "0     2023-01-01 00:00:00  0.445492\n",
       "1     2023-01-01 00:15:00  0.427049\n",
       "2     2023-01-01 00:30:00  0.445492\n",
       "3     2023-01-01 00:45:00  0.420902\n",
       "4     2023-01-01 01:00:00  0.422951\n",
       "...                   ...       ...\n",
       "35035 2023-12-31 22:45:00  0.331148\n",
       "35036 2023-12-31 23:00:00  0.270492\n",
       "35037 2023-12-31 23:15:00  0.365574\n",
       "35038 2023-12-31 23:30:00  0.337295\n",
       "35039 2023-12-31 23:45:00  0.253689\n",
       "\n",
       "[35040 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 96\n",
    "height = 4\n",
    "width = 24\n",
    "n_days_b = 3\n",
    "n_days_s = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageCoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days_b: int,\n",
    "        n_days_s: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days_b\n",
    "        self.d_s = n_days_s\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['Timestamp'].min() + DateOffset(days=self.d_b)\n",
    "        end = self.X['Timestamp'].max() - DateOffset(minutes=self.n_predict*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def generate_gaussian_noise(self, length, std_dev=0.15):\n",
    "        noise = np.random.normal(loc=0.5, scale=std_dev, size=length)\n",
    "        noise = np.clip(noise, 0, 1)\n",
    "        # noise = np.zeros(shape=length)\n",
    "        return pd.DataFrame({\"Load\": noise})\n",
    "    \n",
    "    def __make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def __make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            # noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start_b) & (self.X['Timestamp'] <= training_end)]\n",
    "            # training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            target_data = self.X[(self.X['Timestamp'] >= target_start) & (self.X['Timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data['Load'])\n",
    "                self.X_timestamp.append(training_data['Timestamp'])\n",
    "                self.y_timestamp.append(target_data['Timestamp'])\n",
    "                training_reshaped = np.array(training_data['Load']).reshape(self.d_b, self.h, self.m)\n",
    "                symmetric_3d = self.__make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(symmetric_3d)\n",
    "                target_reshaped = np.array(target_data['Load']).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                symmetric_2d = self.__make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(symmetric_2d)\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    def encode_s(self):\n",
    "        training_sets = []\n",
    "        for steps in self.timestamps:\n",
    "            training_subset = []\n",
    "            point = steps - DateOffset(days=self.d_s-1)\n",
    "            training_start = point - DateOffset(minutes=(self.m-1)*15)\n",
    "            # training\n",
    "            for _ in range(self.d_s-1):\n",
    "                training_end = training_start + DateOffset(minutes=(self.m-1)*15)\n",
    "                training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "                if not training_data.empty:\n",
    "                    symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "                    training_subset.append(symmetric_2d)\n",
    "                training_start = training_start + DateOffset(days=1)\n",
    "            training_end = training_start + DateOffset(minutes=(self.m-self.n_predict-1)*15)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start) & (self.X['Timestamp'] <= training_end)]\n",
    "            noise = self.generate_gaussian_noise(length=self.n_predict)\n",
    "            training_data = pd.concat([training_data, noise], ignore_index=True)\n",
    "            symmetric_2d = self.make_it_symmetric_2d(training_data['Load'])\n",
    "            training_subset.append(symmetric_2d)\n",
    "            training_sets.append(training_subset)\n",
    "        training_sets = np.array(training_sets)\n",
    "        return training_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets\n",
    "    \n",
    "    \"\"\"calculate the final output of model prediction\"\"\"\n",
    "    def __sum_np(self, matrix):\n",
    "        n_pairs = len(matrix) // 2\n",
    "        sums = []\n",
    "        for i in range(n_pairs):\n",
    "            sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        if len(matrix) % 2 != 0:\n",
    "            sums.append(matrix[n_pairs])\n",
    "\n",
    "        return [num for row in sums for num in row]\n",
    "    \n",
    "    def __x_timeseries_to_image(self, vector):\n",
    "        matrix_1d = vector.reshape(self.d_b, self.h, self.m)\n",
    "        image = self.__make_it_symmetric_3d(matrix_1d)\n",
    "        return image\n",
    "    \n",
    "    def pairwise_sum(self, matrix):\n",
    "        summed_3d_np = np.array([self.__sum_np(layer) for layer in matrix]) / 2\n",
    "        return summed_3d_np\n",
    "    \n",
    "    \"\"\"Use predictions from previous steps to add new inputs to rolling predictions\"\"\"\n",
    "    def image_shift(self, original_input, new_input):\n",
    "        input = np.transpose(original_input, (0, 3, 1, 2))\n",
    "        output = []\n",
    "        output.append(self.pairwise_sum(input[0]))\n",
    "        output = np.array(output).flatten()\n",
    "        output = np.concatenate([output, new_input], axis=0)[-len(output):]\n",
    "        image = self.__x_timeseries_to_image(output)\n",
    "        image = image.reshape(1, *image.shape)\n",
    "        image = np.transpose(image, (0, 2, 3, 1))\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 96\n",
      "Ls: 96\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageCoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days_b=n_days_b,\n",
    "    n_days_s=n_days_s,\n",
    "    n_window_shift=n_window_shift\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34656, 8, 24, 3)\n",
      "(34656, 8, 24)\n",
      "(34656, 288)\n",
      "(34656, 288)\n",
      "(34656, 96)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 8, 24, 3)\n",
      "(4608, 8, 24, 3)\n",
      "(30048, 8, 24)\n",
      "(4608, 8, 24)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 96)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('ECALayer')\n",
    "class ECALayer(Layer):\n",
    "    def __init__(self, gamma=2, b=1, **kwargs):\n",
    "        super(ECALayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.t = max(1, int(abs((tf.math.log(float(c)) / tf.math.log(2.0) + self.b) / self.gamma)))\n",
    "        self.conv = Conv1D(filters=1, kernel_size=self.t, padding='same', use_bias=False)\n",
    "        super(ECALayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Global Average Pooling over the spatial dimensions to produce a (batch_size, 1, channels) tensor\n",
    "        x = GlobalAveragePooling2D()(inputs)\n",
    "        x = Reshape((1, -1))(x)\n",
    "        x = self.conv(x)\n",
    "        x = sigmoid(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeeze to make it (batch_size, channels)\n",
    "        \n",
    "        # Multiply weights across channels\n",
    "        return inputs * x[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ECALayer, self).get_config()\n",
    "        config.update({\n",
    "            'gamma': self.gamma,\n",
    "            'b': self.b\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\n",
    "    \"./model/image_inpainting_CNN_LSTM_6steps.keras\",\n",
    "    custom_objects={\n",
    "        \"ECALayer\": ECALayer\n",
    "    },\n",
    "    compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4440~4608\n",
    "def rolling_predict(model, input_data, n_rolling):\n",
    "    final_ouputs = []\n",
    "    for inputs in input_data: \n",
    "        output_roll = []\n",
    "        new_window_input = np.copy(inputs).reshape(1, *inputs.shape)\n",
    "        for _ in range(n_rolling):\n",
    "            y_pred_symmetric = model.predict(new_window_input, verbose=0)\n",
    "            y_pred_roll = encoder.pairwise_sum(y_pred_symmetric).flatten()[:math.ceil(96/n_rolling)]\n",
    "            output_roll.append(y_pred_roll)\n",
    "            new_window_input = encoder.image_shift(new_window_input, y_pred_roll)\n",
    "        output_roll = np.array(output_roll).flatten()\n",
    "        final_ouputs.append(output_roll)\n",
    "    return np.array(final_ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 10:38:24.454040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = rolling_predict(model, X_test_b, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final = encoder.pairwise_sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 96)\n",
      "(4608, 96)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0054\n",
      "rmse: 0.0736\n",
      "mae: 0.0487\n",
      "r2: 0.7755\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test_final.shape)\n",
    "print(y_pred_final.shape)\n",
    "mse = mean_squared_error(y_test_final, y_pred_final)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_final, y_pred_final)\n",
    "r2 = r2_score(y_test_final, y_pred_final)\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLOT_DIR = \"./test_plots/bi_nn_6steps_rolling_6steps/\"\n",
    "RESULT_PLOT_DIR = \"./result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)\n",
    "if not os.path.exists(RESULT_PLOT_DIR):\n",
    "    os.makedirs(RESULT_PLOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(y_pred_final)\n",
    "result_df.to_csv(RESULT_PLOT_DIR+\"bi_nn_6steps_rolling_6steps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(y_test_timestamp.dtype)\n",
    "print(X_test_b_timestamp.dtype)\n",
    "print(y_pred_final.dtype)\n",
    "print(y_test_final.dtype)\n",
    "print(X_test_b_flatten.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = scaler.inverse_transform(y_pred_final)\n",
    "actual_data = scaler.inverse_transform(y_test_final)\n",
    "previous_data = scaler.inverse_transform(X_test_b_flatten)\n",
    "\n",
    "for i in range(actual_data.shape[0]):\n",
    "    history = None\n",
    "    history_timestamp = None\n",
    "    index = i % 192\n",
    "    if index < 47:\n",
    "        history = pred_data[i-index:i+1, 0]\n",
    "        history_timestamp = y_test_timestamp[i-index:i+1, 0]\n",
    "    else:\n",
    "        history = pred_data[i-48:i+1, 0]\n",
    "        history_timestamp = y_test_timestamp[i-48:i+1, 0]\n",
    "        \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    X1 = np.concatenate((X_test_b_timestamp[i][-48:], y_test_timestamp[i]))\n",
    "    y1 = np.concatenate((previous_data[i][-48:], actual_data[i]))\n",
    "    X2 = y_test_timestamp[i]\n",
    "    y_p = pred_data[i]\n",
    "    y_a = actual_data[i]\n",
    "    Xh = np.full(100, X1[len(X1)-96])\n",
    "    yh = np.arange(0, 100, 1)\n",
    "    plt.title(f\"Time Series {i+1} prediction\")\n",
    "    plt.plot(X1, y1, '.-', label='Actual', color='#6eb5c0')\n",
    "    plt.plot(X2, y_p, '.-', label='Predict', color='#174d7c')\n",
    "    plt.plot(history_timestamp, history, '--', label='History', color='#989898')\n",
    "    plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
