{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a list of timestamps every 2 hours within the dataset's range\n",
    "def generate_timestamps(data) -> pd.DatetimeIndex:\n",
    "    start = data['Timestamp'].min() + DateOffset(days=7)\n",
    "    end = data['Timestamp'].max() - DateOffset(hours=3)\n",
    "    timestamps = pd.date_range(start=start, end=end, freq='15min')\n",
    "    return timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = generate_timestamps(data)\n",
    "print(timestamps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sets_for_all_timestamps(timestamps, data):\n",
    "    training_sets = []\n",
    "    target_sets = []\n",
    "    training_sets_time = []\n",
    "    target_sets_time = []\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        # Calculate the range for the current period's data\n",
    "        start_time_current = timestamp - DateOffset(days=2, hours=23, minutes=45)\n",
    "        end_time_current = timestamp\n",
    "\n",
    "        # Calculate the equivalent timestamp for last week\n",
    "        # timestamp_last_week = timestamp - DateOffset(days=7)\n",
    "        # start_time_last_week = timestamp_last_week - DateOffset(days=0, hours=23, minutes=45)\n",
    "        # end_time_last_week = timestamp_last_week\n",
    "\n",
    "        # Calculate the target range (the next 10 steps after the current timestamp)\n",
    "        target_start_time = timestamp + DateOffset(minutes=15)\n",
    "        target_end_time = timestamp + DateOffset(hours=2, minutes=30) \n",
    "\n",
    "        # Filter the data for training and target sets\n",
    "        current_data = data[(data['Timestamp'] >= start_time_current) & (data['Timestamp'] <= end_time_current)]\n",
    "        # last_week_data = data[(data['Timestamp'] >= start_time_last_week) & (data['Timestamp'] <= end_time_last_week)]\n",
    "        target_data = data[(data['Timestamp'] >= target_start_time) & (data['Timestamp'] <= target_end_time)]\n",
    "\n",
    "        # Combine current and last week data for the training set\n",
    "        training_data = pd.concat([current_data]).reset_index(drop=True)\n",
    "        \n",
    "        # Save the training and target sets\n",
    "        if not training_data.empty and not target_data.empty:\n",
    "            training_sets.append(training_data['Load'])\n",
    "            target_sets.append(target_data['Load'])\n",
    "            training_sets_time.append(list(training_data['Timestamp']))\n",
    "            target_sets_time.append(list(target_data['Timestamp']))\n",
    "\n",
    "    training_sets = np.array(training_sets)\n",
    "    target_sets = np.array(target_sets)\n",
    "    training_sets_time = np.array(training_sets_time)\n",
    "    target_sets_time = np.array(target_sets_time)\n",
    "\n",
    "    return training_sets, target_sets, training_sets_time, target_sets_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and target sets for all the timestamps\n",
    "training_sets, target_sets, training_sets_time, target_sets_time = generate_sets_for_all_timestamps(timestamps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(timestamps.shape[0] / 24)\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_test_time = []\n",
    "y_test_time = []\n",
    "minList = []\n",
    "maxList = []\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test.append(training_sets[start:end])\n",
    "    y_test.append(target_sets[start:end])\n",
    "    X_test_time.append(training_sets_time[start:end])\n",
    "    y_test_time.append(target_sets_time[start:end])\n",
    "    training_sets = np.concatenate([training_sets[:start], training_sets[end:]])\n",
    "    target_sets = np.concatenate([target_sets[:start], target_sets[end:]])\n",
    "    training_sets_time = np.concatenate([training_sets_time[:start], training_sets_time[end:]])\n",
    "    target_sets_time = np.concatenate([target_sets_time[:start], target_sets_time[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([i for i in X_test])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_time = np.concatenate([i for i in X_test_time])\n",
    "y_test_time = np.concatenate([i for i in y_test_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_sets\n",
    "X_test = X_test\n",
    "y_train = target_sets\n",
    "X_train_time = training_sets_time\n",
    "y_train_time = target_sets_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_test).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(n_jobs=-1)\n",
    "multioutput_etr = MultiOutputRegressor(etr, n_jobs=-1)\n",
    "multioutput_etr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multioutput_etr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLOT_DIR = \"./test_plots/etr_sliding_window/\"\n",
    "if not os.path.exists(TEST_PLOT_DIR):\n",
    "    os.makedirs(TEST_PLOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = scaler.inverse_transform(y_pred)\n",
    "actual_data = scaler.inverse_transform(y_test)\n",
    "previous_data = scaler.inverse_transform(X_test[:, :])\n",
    "for i in range(actual_data.shape[0]):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    X1 = np.concatenate((X_test_time[i][-30:], y_test_time[i]))\n",
    "    y1 = np.concatenate((previous_data[i][-30:], actual_data[i]))\n",
    "    X2 = y_test_time[i]\n",
    "    y_p = pred_data[i]\n",
    "    y_a = actual_data[i]\n",
    "    Xh = np.full(100, X1[len(X1)-10])\n",
    "    yh = np.arange(0, 100, 1)\n",
    "    plt.title(f\"Time Series {i+1} prediction\")\n",
    "    plt.plot(X1, y1, '--', color='#98afc7')\n",
    "    plt.plot(X2, y_p, label='Predict')\n",
    "    plt.plot(X2, y_a, label='Actual')\n",
    "    plt.scatter(X2, y_p)\n",
    "    plt.scatter(X2, y_a)\n",
    "    plt.plot(Xh, yh, color='#4863a0', alpha=0.5)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Usage (kWh)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(TEST_PLOT_DIR+f\"Time_Series_{i+1}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
