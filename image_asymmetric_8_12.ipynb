{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:04:58.038157: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-11 16:04:58.057985: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-11 16:04:58.058004: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-11 16:04:58.058017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-11 16:04:58.061992: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model ,load_model\n",
    "from keras.layers import Input, Dense, ConvLSTM2D, Conv2D, Conv1D, MaxPooling2D, Layer, GlobalAveragePooling2D, Reshape, Flatten, BatchNormalization, Bidirectional\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.sparse.linalg import cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:04:59.147047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.147154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.149719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.149827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.149903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.149974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.151221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.151322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.151393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.201726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.201830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.201911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 16:04:59.201977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10391 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs\n",
    "DATA_DIR = \"./load.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "data['Load'] = data['Load'] * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['Load'].to_numpy().reshape(-1, 1))\n",
    "data['Load'] = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35040</td>\n",
       "      <td>35040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2023-07-02 11:52:30</td>\n",
       "      <td>0.363028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-04-02 05:56:15</td>\n",
       "      <td>0.260656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2023-07-02 11:52:30</td>\n",
       "      <td>0.319672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-10-01 17:48:45</td>\n",
       "      <td>0.415574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-12-31 23:45:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp          Load\n",
       "count                35040  35040.000000\n",
       "mean   2023-07-02 11:52:30      0.363028\n",
       "min    2023-01-01 00:00:00      0.000000\n",
       "25%    2023-04-02 05:56:15      0.260656\n",
       "50%    2023-07-02 11:52:30      0.319672\n",
       "75%    2023-10-01 17:48:45      0.415574\n",
       "max    2023-12-31 23:45:00      1.000000\n",
       "std                    NaN      0.145213"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! parameter settings\n",
    "n_predict: predict steps\n",
    "height: final height of the image:\n",
    "            height * 2 if the n_predict <= width,\n",
    "            height * 2 + 1 if the n_predict > width\n",
    "width: width of the image\n",
    "n_days: use past n days historical time series data as input (number of channel)\n",
    "n_window_shift: the shift interval of sliding window\n",
    "\"\"\"\n",
    "n_predict = 6\n",
    "height = 8\n",
    "width = 12\n",
    "n_days = 3\n",
    "n_window_shift = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesImageCoder():\n",
    "    def __init__(\n",
    "            self,\n",
    "        X: pd.DataFrame,\n",
    "        n_predict: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        n_days: int,\n",
    "        n_window_shift: str\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.h = height\n",
    "        self.m = width\n",
    "        self.d_b = n_days\n",
    "        self.shift = n_window_shift\n",
    "        self.n_predict = n_predict\n",
    "        self.Lb = self.h * self.m\n",
    "        self.Ls = math.ceil(self.n_predict / self.m) * self.m\n",
    "        self.timestamps = self.generate_timestamps()\n",
    "        print(f\"Lb: {self.Lb}\")\n",
    "        print(f\"Ls: {self.Ls}\")\n",
    "\n",
    "    def generate_timestamps(self):\n",
    "        start = self.X['Timestamp'].min() + DateOffset(days=3)\n",
    "        end = self.X['Timestamp'].max() - DateOffset(minutes=96*15)\n",
    "        timestamps = pd.date_range(start=start, end=end, freq=self.shift)\n",
    "        return timestamps\n",
    "    \n",
    "    def __make_it_symmetric_3d(self, sets_3d):\n",
    "        symmetry_training_sets = []\n",
    "        for slice_2d in np.array(sets_3d):\n",
    "            reversed_slice_2d = slice_2d[::-1]\n",
    "            combined_slice_2d = np.concatenate((slice_2d, reversed_slice_2d), axis=0)\n",
    "            symmetry_training_sets.append(combined_slice_2d)\n",
    "        return np.array(symmetry_training_sets)\n",
    "    \n",
    "    def __make_it_symmetric_2d(self, sets_2d):\n",
    "        reversed_slice_2d = sets_2d[::-1]\n",
    "        combined_slice_2d = np.concatenate((sets_2d, reversed_slice_2d), axis=0)\n",
    "        return np.array(combined_slice_2d)\n",
    "    \n",
    "\n",
    "    def encode_b(self):\n",
    "        training_sets = []\n",
    "        target_sets = []\n",
    "        self.X_timeseries_flatten = []\n",
    "        self.X_timestamp = []\n",
    "        self.y_timestamp = []\n",
    "        for steps in self.timestamps:\n",
    "            training_start_b = steps - DateOffset(days=self.d_b-1, hours=23, minutes=45)\n",
    "            training_end = steps\n",
    "            target_start = training_end + DateOffset(minutes=15)\n",
    "            target_end = steps + DateOffset(minutes=(self.n_predict)*15)\n",
    "            training_data = self.X[(self.X['Timestamp'] >= training_start_b) & (self.X['Timestamp'] <= training_end)]\n",
    "            target_data = self.X[(self.X['Timestamp'] >= target_start) & (self.X['Timestamp'] <= target_end)]\n",
    "            if not training_data.empty and not target_data.empty:\n",
    "                self.X_timeseries_flatten.append(training_data['Load'])\n",
    "                self.X_timestamp.append(training_data['Timestamp'])\n",
    "                self.y_timestamp.append(target_data['Timestamp'])\n",
    "                training_reshaped = np.array(training_data['Load']).reshape(self.d_b, self.h, self.m)\n",
    "                # symmetric_3d = self.__make_it_symmetric_3d(training_reshaped)\n",
    "                training_sets.append(training_reshaped)\n",
    "                target_reshaped = np.array(target_data['Load']).reshape(math.ceil(self.n_predict/self.m), min(self.n_predict, self.m))\n",
    "                # symmetric_2d = self.__make_it_symmetric_2d(target_reshaped)\n",
    "                target_sets.append(target_reshaped.flatten())\n",
    "        training_sets = np.array(training_sets)\n",
    "        target_sets = np.array(target_sets)\n",
    "\n",
    "        self.X_timeseries_flatten = np.array(self.X_timeseries_flatten)\n",
    "        self.X_timestamp = np.array(self.X_timestamp)\n",
    "        self.y_timestamp = np.array(self.y_timestamp)\n",
    "        return training_sets, target_sets\n",
    "    \n",
    "    def encode(self):\n",
    "        training_sets_b, target_sets = self.encode_b()\n",
    "        # training_sets_s = self.encode_s()\n",
    "        training_sets_b = np.transpose(training_sets_b, (0, 2, 3, 1))\n",
    "        # training_sets_s = np.transpose(training_sets_s, (0, 2, 3, 1))\n",
    "        return training_sets_b, target_sets\n",
    "    \n",
    "    \"\"\"calculate the final output of model prediction\"\"\"\n",
    "    def __sum_np(self, matrix):\n",
    "        n_pairs = len(matrix) // 2\n",
    "        sums = []\n",
    "        for i in range(n_pairs):\n",
    "            sums.append(list(map(sum, zip(matrix[i], matrix[-(i + 1)]))))\n",
    "        if len(matrix) % 2 != 0:\n",
    "            sums.append(matrix[n_pairs])\n",
    "\n",
    "        return [num for row in sums for num in row]\n",
    "    \n",
    "    def __x_timeseries_to_image(self, vector):\n",
    "        matrix_1d = vector.reshape(self.d_b, self.h, self.m)\n",
    "        image = self.__make_it_symmetric_3d(matrix_1d)\n",
    "        return image\n",
    "    \n",
    "    def pairwise_sum(self, matrix):\n",
    "        summed_3d_np = np.array([self.__sum_np(layer) for layer in matrix]) / 2\n",
    "        return summed_3d_np\n",
    "    \n",
    "    \"\"\"Use predictions from previous steps to add new inputs to rolling predictions\"\"\"\n",
    "    def image_shift(self, original_input, new_input):\n",
    "        input = np.transpose(original_input, (0, 3, 1, 2))\n",
    "        output = []\n",
    "        output.append(self.pairwise_sum(input[0]))\n",
    "        output = np.array(output).flatten()\n",
    "        output = np.concatenate([output, new_input], axis=0)[-len(output):]\n",
    "        image = self.__x_timeseries_to_image(output)\n",
    "        image = image.reshape(1, *image.shape)\n",
    "        image = np.transpose(image, (0, 2, 3, 1))\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lb: 96\n",
      "Ls: 12\n"
     ]
    }
   ],
   "source": [
    "encoder = TimeSeriesImageCoder(\n",
    "    X=data,\n",
    "    n_predict=n_predict,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    n_days=n_days,\n",
    "    n_window_shift=n_window_shift\n",
    ")\n",
    "encoded_Xb, encoded_y = encoder.encode()\n",
    "X_timeseries = np.copy(encoder.X_timeseries_flatten)\n",
    "X_timestamp = np.copy(encoder.X_timestamp)\n",
    "y_timestamp = np.copy(encoder.y_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34656, 8, 12, 3)\n",
      "(34656, 6)\n",
      "(34656, 288)\n",
      "(34656, 288)\n",
      "(34656, 6)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Xb.shape)\n",
    "print(encoded_y.shape)\n",
    "\n",
    "print(X_timeseries.shape)\n",
    "print(X_timestamp.shape)\n",
    "print(y_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_TIME_STEP = math.floor(encoder.timestamps.shape[0] / 24)\n",
    "X_test_b = []\n",
    "y_test = []\n",
    "X_test_b_flatten = []\n",
    "X_test_b_timestamp = []\n",
    "y_test_timestamp = []\n",
    "\n",
    "for i in range(0, 24):\n",
    "    start = (i+1)*MONTH_TIME_STEP-(192*(i+1))\n",
    "    end = (i+1)*MONTH_TIME_STEP-(192*i)\n",
    "    X_test_b.append(encoded_Xb[start:end])\n",
    "    y_test.append(encoded_y[start:end])\n",
    "    X_test_b_flatten.append(X_timeseries[start:end])\n",
    "    X_test_b_timestamp.append(X_timestamp[start:end])\n",
    "    y_test_timestamp.append(y_timestamp[start:end])\n",
    "\n",
    "\n",
    "    encoded_Xb = np.concatenate([encoded_Xb[:start], encoded_Xb[end:]])\n",
    "    encoded_y = np.concatenate([encoded_y[:start], encoded_y[end:]])\n",
    "    X_timeseries = np.concatenate([X_timeseries[:start], X_timeseries[end:]])\n",
    "    X_timestamp = np.concatenate([X_timestamp[:start], X_timestamp[end:]])\n",
    "    y_timestamp = np.concatenate([y_timestamp[:start], y_timestamp[end:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "X_test_b = np.concatenate([i for i in X_test_b])\n",
    "y_test = np.concatenate([i for i in y_test])\n",
    "X_test_b_flatten = np.concatenate([i for i in X_test_b_flatten])\n",
    "X_test_b_timestamp = np.concatenate([i for i in X_test_b_timestamp])\n",
    "y_test_timestamp = np.concatenate([i for i in y_test_timestamp])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = encoded_Xb\n",
    "y_train = encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30048, 8, 12, 3)\n",
      "(4608, 8, 12, 3)\n",
      "(30048, 6)\n",
      "(4608, 6)\n",
      "(4608, 288)\n",
      "(4608, 288)\n",
      "(4608, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train_b).shape)\n",
    "print(np.array(X_test_b).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(X_test_b_flatten.shape)\n",
    "print(X_test_b_timestamp.shape)\n",
    "print(y_test_timestamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable('ECALayer')\n",
    "class ECALayer(Layer):\n",
    "    def __init__(self, gamma=2, b=1, **kwargs):\n",
    "        super(ECALayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.b = b\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.t = max(1, int(abs((tf.math.log(float(c)) / tf.math.log(2.0) + self.b) / self.gamma)))\n",
    "        self.conv = Conv1D(filters=1, kernel_size=self.t, padding='same', use_bias=False)\n",
    "        super(ECALayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Global Average Pooling over the spatial dimensions to produce a (batch_size, 1, channels) tensor\n",
    "        x = GlobalAveragePooling2D()(inputs)\n",
    "        x = Reshape((1, -1))(x)\n",
    "        x = self.conv(x)\n",
    "        x = sigmoid(x)\n",
    "        x = tf.squeeze(x, axis=1)  # Squeeze to make it (batch_size, channels)\n",
    "        \n",
    "        # Multiply weights across channels\n",
    "        return inputs * x[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ECALayer, self).get_config()\n",
    "        config.update({\n",
    "            'gamma': self.gamma,\n",
    "            'b': self.b\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_b, encoder):\n",
    "    height, width = math.ceil(encoder.n_predict / encoder.m), min(encoder.n_predict, encoder.m)\n",
    "    inputs_b = Input(shape=input_shape_b)\n",
    "    conv1 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(inputs_b)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv1)\n",
    "    conv2 = Reshape((1, *conv2.shape[1:]))(conv2)\n",
    "    nor1 = BatchNormalization()(conv2)\n",
    "    lstm1 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=True, dropout=0.0))(nor1)\n",
    "    nor2 = BatchNormalization()(lstm1)\n",
    "    lstm2 = Bidirectional(ConvLSTM2D(filters=96, kernel_size=3, padding=\"same\", activation=\"tanh\", return_sequences=False, dropout=0.0))(nor2)\n",
    "    nor3 = BatchNormalization()(lstm2)\n",
    "    eca1 = ECALayer()(nor3)\n",
    "    nor4 = BatchNormalization()(eca1)\n",
    "    conv3 = Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"tanh\")(nor4)\n",
    "    conv4 = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")(conv3)\n",
    "    nor5 = BatchNormalization()(conv4)\n",
    "    maxpool1 = MaxPooling2D(pool_size=10, padding=\"same\")(nor5)\n",
    "    flatten1 = Flatten()(maxpool1)\n",
    "    outputs = Dense(height*width, activation=\"linear\")(flatten1)\n",
    "    print(height*width)\n",
    "    model = Model(inputs=inputs_b, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 12, 3)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 12, 32)         896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 12, 64)         18496     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 8, 12, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 8, 12, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1, 8, 12, 192)     1106688   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 8, 12, 192)     768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 8, 12, 192)        1991424   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 12, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " eca_layer (ECALayer)        (None, 8, 12, 192)        768       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 12, 192)        768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 12, 64)         110656    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 12, 32)         18464     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 12, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 2, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3250470 (12.40 MB)\n",
      "Trainable params: 3249126 (12.39 MB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", patience=10, min_delta=5e-5)\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5, verbose=1, min_lr=1e-7)\n",
    "callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    "model = create_model(input_shape_b=X_train_b.shape[1:], encoder=encoder)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:05:24.641223: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/model/bidirectional_1/backward_conv_lstm2d_1/while_grad/body/_948/input/_2185' -> 'gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/model/bidirectional_1/backward_conv_lstm2d_1/while_grad/body/_948/gradient_tape/model/bidirectional_1/backward_conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/model/bidirectional_1/forward_conv_lstm2d_1/while_grad/body/_753/input/_2066' -> 'gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/model/bidirectional_1/forward_conv_lstm2d_1/while_grad/body/_753/gradient_tape/model/bidirectional_1/forward_conv_lstm2d_1/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional/backward_conv_lstm2d/while/model/bidirectional/backward_conv_lstm2d/while_grad/body/_1338/input/_2423' -> 'gradient_tape/model/bidirectional/backward_conv_lstm2d/while/model/bidirectional/backward_conv_lstm2d/while_grad/body/_1338/gradient_tape/model/bidirectional/backward_conv_lstm2d/while/gradients/AddN', 'Func/gradient_tape/model/bidirectional/forward_conv_lstm2d/while/model/bidirectional/forward_conv_lstm2d/while_grad/body/_1143/input/_2304' -> 'gradient_tape/model/bidirectional/forward_conv_lstm2d/while/model/bidirectional/forward_conv_lstm2d/while_grad/body/_1143/gradient_tape/model/bidirectional/forward_conv_lstm2d/while/gradients/AddN', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/clip_by_value' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_6' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_377/model/bidirectional_1/forward_conv_lstm2d_1/while/add_4', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/clip_by_value' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_3', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_6' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/add_4', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/clip_by_value_2' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_565/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5'}.\n",
      "2024-06-11 16:05:25.025528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 17s 43ms/step - loss: 0.0219 - lr: 5.0000e-05\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.0032 - lr: 5.0000e-05\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0030 - lr: 5.0000e-05\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0028 - lr: 5.0000e-05\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0027 - lr: 5.0000e-05\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0025 - lr: 5.0000e-05\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0024 - lr: 5.0000e-05\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0023 - lr: 5.0000e-05\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0022 - lr: 5.0000e-05\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0021 - lr: 5.0000e-05\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0020 - lr: 5.0000e-05\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0019 - lr: 5.0000e-05\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0018 - lr: 5.0000e-05\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0017 - lr: 5.0000e-05\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0016 - lr: 5.0000e-05\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0015 - lr: 5.0000e-05\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0015 - lr: 5.0000e-05\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0015 - lr: 5.0000e-05\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0014 - lr: 5.0000e-05\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0014 - lr: 5.0000e-05\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0013 - lr: 5.0000e-05\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0012 - lr: 5.0000e-05\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 15s 46ms/step - loss: 0.0011 - lr: 5.0000e-05\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0010 - lr: 5.0000e-05\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0010 - lr: 5.0000e-05\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0010 - lr: 5.0000e-05\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 9.9152e-04 - lr: 5.0000e-05\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 9.5249e-04 - lr: 5.0000e-05\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 9.6033e-04\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 9.6033e-04 - lr: 5.0000e-05\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 15s 46ms/step - loss: 7.6031e-04 - lr: 1.5000e-05\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 7.1494e-04 - lr: 1.5000e-05\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 7.0310e-04 - lr: 1.5000e-05\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 6.8916e-04 - lr: 1.5000e-05\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 6.8055e-04 - lr: 1.5000e-05\n",
      "Epoch 58/120\n",
      "312/313 [============================>.] - ETA: 0s - loss: 6.7554e-04\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 6.7501e-04 - lr: 1.5000e-05\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 6.2427e-04 - lr: 4.5000e-06\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 15s 46ms/step - loss: 6.2005e-04 - lr: 4.5000e-06\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 6.1485e-04 - lr: 4.5000e-06\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 6.1639e-04 - lr: 4.5000e-06\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 6.1055e-04 - lr: 4.5000e-06\n",
      "Epoch 64/120\n",
      "312/313 [============================>.] - ETA: 0s - loss: 6.0788e-04\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 6.0734e-04 - lr: 4.5000e-06\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 5.8950e-04 - lr: 1.3500e-06\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 5.9021e-04 - lr: 1.3500e-06\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 5.8544e-04 - lr: 1.3500e-06\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 5.8303e-04 - lr: 1.3500e-06\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 5.8596e-04\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.0499998021914507e-07.\n",
      "313/313 [==============================] - 15s 46ms/step - loss: 5.8596e-04 - lr: 1.3500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_b,\n",
    "    y_train,\n",
    "    verbose=1,\n",
    "    epochs=120,\n",
    "    batch_size=96,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18/144 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:21:54.478480: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/mul_2' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_5', 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/forward_conv_lstm2d_1/while/body/_97/model/bidirectional_1/forward_conv_lstm2d_1/while/add_6', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/Tanh_1' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_5', 'Func/model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/input/_326' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/mul_2', 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/convolution_7' -> 'model/bidirectional_1/backward_conv_lstm2d_1/while/body/_145/model/bidirectional_1/backward_conv_lstm2d_1/while/add_6'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 6)\n",
      "(4608, 6)\n",
      "--------------------------------------------------------------------------------------\n",
      "mse: 0.0033\n",
      "rmse: 0.0574\n",
      "mae: 0.0375\n",
      "mape:  0.1013\n",
      "r2: 0.8615\n",
      "--------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------\n",
      "mse_inv: 31.3951\n",
      "rmse_inv: 5.6031\n",
      "mae_inv: 3.6569\n",
      "mape_inv:  0.1011\n",
      "r2_inv: 0.8615\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse: {mse:.4f}')\n",
    "print(f'rmse: {rmse:.4f}')\n",
    "print(f'mae: {mae:.4f}')\n",
    "print(f'mape: {mape: .4f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "print(\"-\" * 86)\n",
    "\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "mse_inv = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse_inv = math.sqrt(mse_inv)\n",
    "mae_inv = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mape_inv = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "r2_inv = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(\"-\" * 86)\n",
    "print(f'mse_inv: {mse_inv:.4f}')\n",
    "print(f'rmse_inv: {rmse_inv:.4f}')\n",
    "print(f'mae_inv: {mae_inv:.4f}')\n",
    "print(f'mape_inv: {mape_inv: .4f}')\n",
    "print(f'r2_inv: {r2_inv:.4f}')\n",
    "print(\"-\" * 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_per_steps(true_values, predicted_values):\n",
    "    n_steps = true_values.shape[1]\n",
    "\n",
    "    mse = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    mape = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        true_step = true_values[:, i]\n",
    "        predicted_step = predicted_values[:, i]\n",
    "\n",
    "        mse_step = mean_squared_error(true_step, predicted_step)\n",
    "        rmse_step = np.sqrt(mse_step)\n",
    "        mae_step = mean_absolute_error(true_step, predicted_step)\n",
    "        mape_step = mean_absolute_percentage_error(true_step, predicted_step)\n",
    "\n",
    "        mse.append(mse_step)\n",
    "        rmse.append(rmse_step)\n",
    "        mae.append(mae_step)\n",
    "        mape.append(mape_step)\n",
    "\n",
    "    return np.array(mse), np.array(rmse), np.array(mae), np.array(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_per_steps, rmse_per_steps, mae_per_steps, mape_per_steps = calculate_metrics_per_steps(y_test_inv, y_pred_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.14192023 25.23415967 30.30320968 35.45370119 37.69444161 38.5431557 ]\n",
      "[4.59803439 5.02336139 5.50483512 5.95430107 6.13957992 6.20831343]\n",
      "[3.0790384  3.25091791 3.63200671 3.89376614 4.01479133 4.07079737]\n",
      "[0.08645055 0.08884361 0.10076629 0.10746813 0.11039922 0.11242027]\n"
     ]
    }
   ],
   "source": [
    "print(mse_per_steps)\n",
    "print(rmse_per_steps)\n",
    "print(mae_per_steps)\n",
    "print(mape_per_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/image_asymmetric_8_12_6steps.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
